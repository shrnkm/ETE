{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten   \n",
    "from tensorflow.keras.layers import Layer, ZeroPadding2D, Input, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an implication of Pytorch CrossMapLRN2d with Keras\n",
    "class LRN2D(Layer):\n",
    "    \"\"\"\n",
    "    This code is adapted from pylearn2.\n",
    "    License at: https://github.com/lisa-lab/pylearn2/blob/master/LICENSE.txt\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=1e-4, k=2, beta=0.75, n=5):\n",
    "        if n % 2 == 0:\n",
    "            raise NotImplementedError('LRN2D only works with odd n. n provided: ' + str(n))\n",
    "        super(LRN2D, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.k = k\n",
    "        self.beta = beta\n",
    "        self.n = n\n",
    "\n",
    "    def get_output(self, train):\n",
    "        X = self.get_input(train)\n",
    "        b, ch, r, c = X.shape\n",
    "        half_n = self.n // 2\n",
    "        input_sqr = T.sqr(X)\n",
    "        extra_channels = T.alloc(0., b, ch + 2*half_n, r, c)\n",
    "        input_sqr = T.set_subtensor(extra_channels[:, half_n:half_n+ch, :, :], input_sqr)\n",
    "        scale = self.k\n",
    "        for i in range(self.n):\n",
    "            scale += self.alpha * input_sqr[:, i:i+ch, :, :]\n",
    "        scale = scale ** self.beta\n",
    "        return X / scale\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'name': self.__class__.__name__,\n",
    "                'alpha': self.alpha,\n",
    "                'k': self.k,\n",
    "                'beta': self.beta,\n",
    "                'n': self.n}\n",
    "\n",
    "    \n",
    "\n",
    "# another implication of Pytorch CrossMapLRN2d with Keras\n",
    "class LocalResponseNormalization(Layer):\n",
    "  \n",
    "    def __init__(self, n=5, alpha=1e-4, beta=0.75, k=2, **kwargs):\n",
    "        self.n = n\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.k = k\n",
    "        super(LocalResponseNormalization, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.shape = input_shape\n",
    "        super(LocalResponseNormalization, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        _, r, c, f = self.shape \n",
    "        squared = K.square(x)\n",
    "        pooled = K.pool2d(squared, (self.n, self.n), strides=(1,1), padding='same', pool_mode='avg')\n",
    "        summed = K.sum(pooled, axis=3, keepdims=True)\n",
    "        averaged = self.alpha * K.repeat_elements(summed, f, axis=3)\n",
    "        denom = K.pow(self.k + averaged, self.beta)\n",
    "        return x / denom \n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "\n",
    "\n",
    "# Function for changing learning rate over epochs\n",
    "def lr_decay(epoch):\n",
    "    decay = .1\n",
    "    lr = base_lr * math.pow(decay, (epoch // 30))   \n",
    "    return lr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0f396eafb04c8eb2afc5ce5a9f87af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load the scaled dataset\n",
    "path = 'D:/ETE/Data/Data_Mini/pickles/'\n",
    "pickles = ['left_eye', 'right_eye', 'face', 'grid_paper', 'labels']\n",
    "\n",
    "for pkl in tqdm(pickles):\n",
    "    with open(path + pkl + '.pkl','rb') as f:\n",
    "        exec(pkl + ' = pickle.load(f)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. The Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Eye Net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_input = Input(shape=(64,64,3))\n",
    "eye_cnn1_out = Conv2D(filters=96,\n",
    "                       kernel_size=11,\n",
    "                       strides=4,\n",
    "                       padding='valid',\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4),\n",
    "                       input_shape=(224,224,3))(eye_input)\n",
    "eye_max1_out = MaxPool2D(pool_size=3, strides=2)(eye_cnn1_out)\n",
    "eye_lrn1_out = LRN2D(n=5, alpha=1e-4, beta=0.75, k=1.0)(eye_max1_out)\n",
    "eye_zro1_out = ZeroPadding2D(padding=2)(eye_lrn1_out)\n",
    "eye_cnn2_out = Conv2D(filters=256,\n",
    "                      kernel_size=5,\n",
    "                      strides=1,\n",
    "                      padding='valid',\n",
    "                      #groups=2,\n",
    "                      activation='relu',\n",
    "                      kernel_regularizer=regularizers.l2(1e-4))(eye_zro1_out)\n",
    "eye_max2_out = MaxPool2D(pool_size=3, strides=2)(eye_cnn2_out)\n",
    "eye_lrn2_out = LRN2D(n=5, alpha=1e-4, beta=0.75, k=1.0)(eye_max2_out)\n",
    "eye_cnn3_out = Conv2D(filters=384,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same',\n",
    "                      activation='relu',\n",
    "                      kernel_regularizer=regularizers.l2(1e-4))(eye_lrn2_out)\n",
    "eye_cnn4_out = Conv2D(filters=64,\n",
    "                      kernel_size=1,\n",
    "                      strides=1,\n",
    "                      padding='valid',\n",
    "                      activation='relu',\n",
    "                      kernel_regularizer=regularizers.l2(1e-4))(eye_cnn3_out)\n",
    "eye_out = Flatten()(eye_cnn4_out)\n",
    "\n",
    "model_eye = Model(eye_input, eye_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Face Net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_input = Input(shape=(64,64,3))\n",
    "face_cnn1_out = Conv2D(filters=96,\n",
    "                       kernel_size=11,\n",
    "                       strides=4,\n",
    "                       padding='valid',\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4),\n",
    "                       input_shape=(224,224,3))(face_input)\n",
    "face_max1_out = MaxPool2D(pool_size=3, strides=2)(face_cnn1_out)\n",
    "face_lrn1_out = LRN2D(n=5, alpha=1e-4, beta=0.75, k=1.0)(face_max1_out)\n",
    "face_zro1_out = ZeroPadding2D(padding=2)(face_lrn1_out)\n",
    "face_cnn2_out = Conv2D(filters=256,\n",
    "                       kernel_size=5,\n",
    "                       strides=1,\n",
    "                       padding='valid',\n",
    "                       #groups=2,\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4))(face_zro1_out)\n",
    "face_max2_out = MaxPool2D(pool_size=3, strides=2)(face_cnn2_out)\n",
    "face_lrn2_out = LRN2D(n=5, alpha=1e-4, beta=0.75, k=1.0)(face_max2_out)\n",
    "face_cnn3_out = Conv2D(filters=384,\n",
    "                       kernel_size=3,\n",
    "                       strides=1,\n",
    "                       padding='same',\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4))(face_lrn2_out)\n",
    "face_cnn4_out = Conv2D(filters=64,\n",
    "                       kernel_size=1,\n",
    "                       strides=1,\n",
    "                       padding='valid',\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4))(face_cnn3_out)\n",
    "face_flt_out = Flatten()(face_cnn4_out)\n",
    "face_dns_out = Dense(128, activation = 'relu',\n",
    "                     kernel_regularizer=regularizers.l2(1e-4))(face_flt_out)\n",
    "face_out = Dense(64, activation = 'relu')(face_dns_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Papaer Grid Net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_input = Input(shape=(25,25))\n",
    "grid_flt_out = Flatten()(grid_input)\n",
    "grid_dns_out = Dense(256, activation = 'relu',\n",
    "                     kernel_regularizer=regularizers.l2(1e-4))(grid_flt_out)\n",
    "grid_out = Dense(128, activation = 'relu',\n",
    "                 kernel_regularizer=regularizers.l2(1e-4))(grid_dns_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Merge the Eyes' Nets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_left_input = Input(shape=(64,64,3))\n",
    "eye_right_input = Input(shape=(64,64,3))\n",
    "eye_left_out = model_eye(eye_left_input)\n",
    "eye_right_out = model_eye(eye_right_input)\n",
    "\n",
    "concat_eyes = concatenate([eye_left_out, eye_right_out])\n",
    "\n",
    "eyes_out = Dense(128, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(1e-4))(concat_eyes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Merge the Eyes, Face, and the Grid Nets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_all = concatenate([eyes_out, face_out, grid_out])\n",
    "\n",
    "final_dns_out = Dense(128, activation='relu',\n",
    "                      kernel_regularizer=regularizers.l2(1e-4))(concat_all)\n",
    "final_out = Dense(2, activation='relu',\n",
    "                  kernel_regularizer=regularizers.l2(1e-4))(final_dns_out)\n",
    "\n",
    "final_model = Model([eye_left_input, eye_right_input, face_input, grid_input], final_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 14, 14, 96)   34944       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 6, 6, 96)     0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lr_n2d_2 (LRN2D)                (None, 6, 6, 96)     0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 10, 10, 96)   0           lr_n2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 6, 6, 256)    614656      zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 2, 2, 256)    0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lr_n2d_3 (LRN2D)                (None, 2, 2, 256)    0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 2, 2, 384)    885120      lr_n2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 2, 2, 64)     24640       conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 25, 25)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Model)                   (None, 256)          1559360     input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 256)          0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 625)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 512)          0           model[1][0]                      \n",
      "                                                                 model[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          32896       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          160256      flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          65664       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           8256        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          32896       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 320)          0           dense_4[0][0]                    \n",
      "                                                                 dense_1[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          41088       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2)            258         dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,460,034\n",
      "Trainable params: 3,460,034\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_callback = LearningRateScheduler(lr_decay)\n",
    "checkpointer = ModelCheckpoint(filepath='Weights.hdf5', monitor='val_loss',\n",
    "                               verbose=1, save_best_only=True)\n",
    "base_lr = 0.0001\n",
    "momentum = 0.9\n",
    "\n",
    "# sgd = SGD(lr=base_lr, momentum=momentum)\n",
    "sgd = SGD(lr=1e-1, decay=5e-4, momentum=9e-1, nesterov=True)\n",
    "adam = Adam(lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7995 samples, validate on 1999 samples\n",
      "Epoch 1/25\n",
      "7808/7995 [============================>.] - ETA: 0s - loss: 30.4278 - mae: 4.0384\n",
      "Epoch 00001: val_loss improved from inf to 28.73477, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 7s 872us/sample - loss: 30.3131 - mae: 4.0313 - val_loss: 28.7348 - val_mae: 3.9256\n",
      "Epoch 2/25\n",
      "7808/7995 [============================>.] - ETA: 0s - loss: 30.2187 - mae: 4.0222\n",
      "Epoch 00002: val_loss improved from 28.73477 to 28.72146, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 3s 373us/sample - loss: 30.2436 - mae: 4.0219 - val_loss: 28.7215 - val_mae: 3.9252\n",
      "Epoch 3/25\n",
      "7808/7995 [============================>.] - ETA: 0s - loss: 30.1782 - mae: 4.0200\n",
      "Epoch 00003: val_loss did not improve from 28.72146\n",
      "7995/7995 [==============================] - 3s 329us/sample - loss: 30.2248 - mae: 4.0194 - val_loss: 28.7247 - val_mae: 3.9279\n",
      "Epoch 4/25\n",
      "7808/7995 [============================>.] - ETA: 0s - loss: 30.2172 - mae: 4.0209\n",
      "Epoch 00004: val_loss improved from 28.72146 to 28.70607, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 3s 389us/sample - loss: 30.2041 - mae: 4.0169 - val_loss: 28.7061 - val_mae: 3.9270\n",
      "Epoch 5/25\n",
      "7936/7995 [============================>.] - ETA: 0s - loss: 30.1822 - mae: 4.0193\n",
      "Epoch 00005: val_loss improved from 28.70607 to 28.69683, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 3s 406us/sample - loss: 30.2060 - mae: 4.0194 - val_loss: 28.6968 - val_mae: 3.9261\n",
      "Epoch 6/25\n",
      "7808/7995 [============================>.] - ETA: 0s - loss: 30.1776 - mae: 4.0140\n",
      "Epoch 00006: val_loss did not improve from 28.69683\n",
      "7995/7995 [==============================] - 3s 331us/sample - loss: 30.1789 - mae: 4.0161 - val_loss: 28.7049 - val_mae: 3.9280\n",
      "Epoch 7/25\n",
      "7808/7995 [============================>.] - ETA: 0s - loss: 30.2367 - mae: 4.0164\n",
      "Epoch 00007: val_loss improved from 28.69683 to 28.61141, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 3s 366us/sample - loss: 30.1333 - mae: 4.0085 - val_loss: 28.6114 - val_mae: 3.9114\n",
      "Epoch 8/25\n",
      "7808/7995 [============================>.] - ETA: 0s - loss: 30.0856 - mae: 3.9916\n",
      "Epoch 00008: val_loss did not improve from 28.61141\n",
      "7995/7995 [==============================] - 3s 332us/sample - loss: 30.0553 - mae: 3.9919 - val_loss: 28.6421 - val_mae: 3.9118\n",
      "Epoch 9/25\n",
      "7808/7995 [============================>.] - ETA: 0s - loss: 30.0790 - mae: 3.9912\n",
      "Epoch 00009: val_loss did not improve from 28.61141\n",
      "7995/7995 [==============================] - 3s 329us/sample - loss: 30.0275 - mae: 3.9868 - val_loss: 28.6729 - val_mae: 3.9172\n",
      "Epoch 10/25\n",
      "7808/7995 [============================>.] - ETA: 0s - loss: 29.9994 - mae: 3.9800\n",
      "Epoch 00010: val_loss improved from 28.61141 to 28.50886, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 3s 385us/sample - loss: 29.9964 - mae: 3.9812 - val_loss: 28.5089 - val_mae: 3.8883\n",
      "Epoch 11/25\n",
      "7808/7995 [============================>.] - ETA: 0s - loss: 29.8843 - mae: 3.9670\n",
      "Epoch 00011: val_loss improved from 28.50886 to 28.45941, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 3s 378us/sample - loss: 29.9457 - mae: 3.9711 - val_loss: 28.4594 - val_mae: 3.8808\n",
      "Epoch 12/25\n",
      "7808/7995 [============================>.] - ETA: 0s - loss: 29.9326 - mae: 3.9639\n",
      "Epoch 00012: val_loss improved from 28.45941 to 28.42557, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 3s 374us/sample - loss: 29.9076 - mae: 3.9635 - val_loss: 28.4256 - val_mae: 3.8717\n",
      "Epoch 13/25\n",
      "7808/7995 [============================>.] - ETA: 0s - loss: 29.8095 - mae: 3.9501\n",
      "Epoch 00013: val_loss did not improve from 28.42557\n",
      "7995/7995 [==============================] - 3s 333us/sample - loss: 29.8648 - mae: 3.9531 - val_loss: 28.4801 - val_mae: 3.8792\n",
      "Epoch 14/25\n",
      "7808/7995 [============================>.] - ETA: 0s - loss: 29.7765 - mae: 3.9438\n",
      "Epoch 00014: val_loss improved from 28.42557 to 28.41895, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 3s 395us/sample - loss: 29.8335 - mae: 3.9473 - val_loss: 28.4190 - val_mae: 3.8666\n",
      "Epoch 15/25\n",
      "7808/7995 [============================>.] - ETA: 0s - loss: 29.8080 - mae: 3.9385\n",
      "Epoch 00015: val_loss improved from 28.41895 to 28.39882, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 3s 367us/sample - loss: 29.7892 - mae: 3.9364 - val_loss: 28.3988 - val_mae: 3.8606\n",
      "Epoch 16/25\n",
      "7808/7995 [============================>.] - ETA: 0s - loss: 29.7773 - mae: 3.9251\n",
      "Epoch 00016: val_loss improved from 28.39882 to 28.35363, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 3s 376us/sample - loss: 29.7371 - mae: 3.9246 - val_loss: 28.3536 - val_mae: 3.8491\n",
      "Epoch 17/25\n",
      "7808/7995 [============================>.] - ETA: 0s - loss: 29.7100 - mae: 3.9151\n",
      "Epoch 00017: val_loss improved from 28.35363 to 28.35308, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 3s 388us/sample - loss: 29.7043 - mae: 3.9164 - val_loss: 28.3531 - val_mae: 3.8486\n",
      "Epoch 18/25\n",
      "7808/7995 [============================>.] - ETA: 0s - loss: 29.6088 - mae: 3.9017\n",
      "Epoch 00018: val_loss did not improve from 28.35308\n",
      "7995/7995 [==============================] - 3s 331us/sample - loss: 29.6534 - mae: 3.9034 - val_loss: 28.3819 - val_mae: 3.8571\n",
      "Epoch 19/25\n",
      "7808/7995 [============================>.] - ETA: 0s - loss: 29.6772 - mae: 3.8962\n",
      "Epoch 00019: val_loss did not improve from 28.35308\n",
      "7995/7995 [==============================] - 3s 329us/sample - loss: 29.6090 - mae: 3.8918 - val_loss: 28.3800 - val_mae: 3.8553\n",
      "Epoch 20/25\n",
      "7808/7995 [============================>.] - ETA: 0s - loss: 29.4935 - mae: 3.8767\n",
      "Epoch 00020: val_loss did not improve from 28.35308\n",
      "7995/7995 [==============================] - 3s 336us/sample - loss: 29.5609 - mae: 3.8795 - val_loss: 28.3549 - val_mae: 3.8508\n",
      "Epoch 21/25\n",
      "7808/7995 [============================>.] - ETA: 0s - loss: 29.4854 - mae: 3.8588\n",
      "Epoch 00021: val_loss did not improve from 28.35308\n",
      "7995/7995 [==============================] - 3s 331us/sample - loss: 29.5024 - mae: 3.8616 - val_loss: 28.3732 - val_mae: 3.8553\n",
      "Epoch 22/25\n",
      "7808/7995 [============================>.] - ETA: 0s - loss: 29.5008 - mae: 3.8566\n",
      "Epoch 00022: val_loss did not improve from 28.35308\n",
      "7995/7995 [==============================] - 3s 329us/sample - loss: 29.4671 - mae: 3.8532 - val_loss: 28.4357 - val_mae: 3.8738\n",
      "Epoch 23/25\n",
      "7808/7995 [============================>.] - ETA: 0s - loss: 29.4363 - mae: 3.8447\n",
      "Epoch 00023: val_loss did not improve from 28.35308\n",
      "7995/7995 [==============================] - 3s 334us/sample - loss: 29.4366 - mae: 3.8449 - val_loss: 28.5094 - val_mae: 3.8893\n",
      "Epoch 24/25\n",
      "7808/7995 [============================>.] - ETA: 0s - loss: 29.3272 - mae: 3.8256\n",
      "Epoch 00024: val_loss did not improve from 28.35308\n",
      "7995/7995 [==============================] - 3s 332us/sample - loss: 29.3764 - mae: 3.8267 - val_loss: 28.3646 - val_mae: 3.8506\n",
      "Epoch 25/25\n",
      "7808/7995 [============================>.] - ETA: 0s - loss: 29.3118 - mae: 3.8182\n",
      "Epoch 00025: val_loss did not improve from 28.35308\n",
      "7995/7995 [==============================] - 3s 333us/sample - loss: 29.3561 - mae: 3.8208 - val_loss: 28.5044 - val_mae: 3.8871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x267efd05b08>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.compile(optimizer=adam, loss='mse', metrics=['mae'])\n",
    "\n",
    "final_model.fit(x=[left_eye, right_eye, face, grid_paper], \n",
    "          y=labels,\n",
    "          batch_size=128,\n",
    "          epochs=25,\n",
    "          validation_split=0.2,\n",
    "          shuffle=True,\n",
    "          callbacks=[lr_callback, checkpointer])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
