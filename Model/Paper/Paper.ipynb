{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten   \n",
    "from tensorflow.keras.layers import Layer, ZeroPadding2D, Input, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an implication of Pytorch CrossMapLRN2d with Keras\n",
    "class LRN2D(Layer):\n",
    "    \"\"\"\n",
    "    This code is adapted from pylearn2.\n",
    "    License at: https://github.com/lisa-lab/pylearn2/blob/master/LICENSE.txt\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=1e-4, k=2, beta=0.75, n=5):\n",
    "        if n % 2 == 0:\n",
    "            raise NotImplementedError('LRN2D only works with odd n. n provided: ' + str(n))\n",
    "        super(LRN2D, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.k = k\n",
    "        self.beta = beta\n",
    "        self.n = n\n",
    "\n",
    "    def get_output(self, train):\n",
    "        X = self.get_input(train)\n",
    "        b, ch, r, c = X.shape\n",
    "        half_n = self.n // 2\n",
    "        input_sqr = T.sqr(X)\n",
    "        extra_channels = T.alloc(0., b, ch + 2*half_n, r, c)\n",
    "        input_sqr = T.set_subtensor(extra_channels[:, half_n:half_n+ch, :, :], input_sqr)\n",
    "        scale = self.k\n",
    "        for i in range(self.n):\n",
    "            scale += self.alpha * input_sqr[:, i:i+ch, :, :]\n",
    "        scale = scale ** self.beta\n",
    "        return X / scale\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'name': self.__class__.__name__,\n",
    "                'alpha': self.alpha,\n",
    "                'k': self.k,\n",
    "                'beta': self.beta,\n",
    "                'n': self.n}\n",
    "\n",
    "    \n",
    "\n",
    "# another implication of Pytorch CrossMapLRN2d with Keras\n",
    "class LocalResponseNormalization(Layer):\n",
    "  \n",
    "    def __init__(self, n=5, alpha=1e-4, beta=0.75, k=2, **kwargs):\n",
    "        self.n = n\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.k = k\n",
    "        super(LocalResponseNormalization, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.shape = input_shape\n",
    "        super(LocalResponseNormalization, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        _, r, c, f = self.shape \n",
    "        squared = K.square(x)\n",
    "        pooled = K.pool2d(squared, (self.n, self.n), strides=(1,1), padding='same', pool_mode='avg')\n",
    "        summed = K.sum(pooled, axis=3, keepdims=True)\n",
    "        averaged = self.alpha * K.repeat_elements(summed, f, axis=3)\n",
    "        denom = K.pow(self.k + averaged, self.beta)\n",
    "        return x / denom \n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "\n",
    "\n",
    "# Function for changing learning rate over epochs\n",
    "def lr_decay(epoch):\n",
    "    decay = .1\n",
    "    lr = base_lr * math.pow(decay, (epoch // 30))   \n",
    "    return lr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2192153396e24f3d927e49e75e52e431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# read the pkl file and load the data\n",
    "path = 'D:/ETE/Data/Data_Mini/'\n",
    "pickles = ['Images', 'LeftEye', 'RightEye', 'Face', 'GridMTCNN', 'GridPaper']\n",
    "# pickles = ['LeftEye', 'RightEye', 'Face', 'GridPaper', 'labels']\n",
    "\n",
    "for pkl in tqdm(pickles):\n",
    "    with open(path + pkl + '.pkl','rb') as f:\n",
    "        exec(pkl + ' = pickle.load(f)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pkl in pickles:\n",
    "    exec('print(pkl, \\'is a\\', type(' + pkl+ '), \\'with shape:\\', ' + pkl + '.shape)')\n",
    "\n",
    "idx = np.random.randint(9994)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15,45))\n",
    "for i in range(3):\n",
    "    axs[i].axis('off')\n",
    "axs[0].title.set_text('Right Eye')    \n",
    "axs[0].imshow(RightEye[idx])\n",
    "axs[1].title.set_text('Left Eye')\n",
    "axs[1].imshow(LeftEye[idx])\n",
    "axs[2].title.set_text('Face')\n",
    "axs[2].imshow(Face[idx])\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15,45))\n",
    "for i in range(3):\n",
    "    axs[i].set_xticks([])\n",
    "    axs[i].set_yticks([])\n",
    "axs[0].title.set_text('Frame')\n",
    "axs[0].imshow(Images[idx])\n",
    "axs[1].title.set_text('MTCNN Grid')\n",
    "axs[1].imshow(GridMTCNN[idx])\n",
    "axs[2].title.set_text('Paper Grid')\n",
    "axs[2].imshow(GridPaper[idx]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. The Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Eye Net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_input = Input(shape=(224,224,3))\n",
    "eye_cnn1_out = Conv2D(filters=96,\n",
    "                       kernel_size=11,\n",
    "                       strides=4,\n",
    "                       padding='valid',\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4),\n",
    "                       input_shape=(224,224,3))(eye_input)\n",
    "eye_max1_out = MaxPool2D(pool_size=3, strides=2)(eye_cnn1_out)\n",
    "eye_lrn1_out = LRN2D(n=5, alpha=1e-4, beta=0.75, k=1.0)(eye_max1_out)\n",
    "eye_zro1_out = ZeroPadding2D(padding=2)(eye_lrn1_out)\n",
    "eye_cnn2_out = Conv2D(filters=256,\n",
    "                      kernel_size=5,\n",
    "                      strides=1,\n",
    "                      padding='valid',\n",
    "                      #groups=2,\n",
    "                      activation='relu',\n",
    "                      kernel_regularizer=regularizers.l2(1e-4))(eye_zro1_out)\n",
    "eye_max2_out = MaxPool2D(pool_size=3, strides=2)(eye_cnn2_out)\n",
    "eye_lrn2_out = LRN2D(n=5, alpha=1e-4, beta=0.75, k=1.0)(eye_max2_out)\n",
    "eye_cnn3_out = Conv2D(filters=384,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same',\n",
    "                      activation='relu',\n",
    "                      kernel_regularizer=regularizers.l2(1e-4))(eye_lrn2_out)\n",
    "eye_cnn4_out = Conv2D(filters=64,\n",
    "                      kernel_size=1,\n",
    "                      strides=1,\n",
    "                      padding='valid',\n",
    "                      activation='relu',\n",
    "                      kernel_regularizer=regularizers.l2(1e-4))(eye_cnn3_out)\n",
    "eye_out = Flatten()(eye_cnn4_out)\n",
    "\n",
    "model_eye = Model(eye_input, eye_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Left Eye Net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Run Cell\n",
    "# in the original model both eyes share the same model, that is Eye Net\n",
    "\n",
    "eyel_input = Input(shape=(224,224,3))\n",
    "eyel_cnn1_out = Conv2D(filters=96,\n",
    "                       kernel_size=11,\n",
    "                       strides=4,\n",
    "                       padding='valid',\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4),\n",
    "                       input_shape=(224,224,3))(eyel_input)\n",
    "eyel_max1_out = MaxPool2D(pool_size=3, strides=2)(eyel_cnn1_out)\n",
    "eyel_lrn1_out = LRN2D(n=5, alpha=1e-4, beta=0.75, k=1.0)(eyel_max1_out)\n",
    "eyel_zro1_out = ZeroPadding2D(padding=2)(eyel_lrn1_out)\n",
    "eyel_cnn2_out = Conv2D(filters=256,\n",
    "                       kernel_size=5,\n",
    "                       strides=1,\n",
    "                       padding='valid',\n",
    "                       #groups=2,\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4))(eyel_zro1_out)\n",
    "eyel_max2_out = MaxPool2D(pool_size=3, strides=2)(eyel_cnn2_out)\n",
    "eyel_lrn2_out = LRN2D(n=5, alpha=1e-4, beta=0.75, k=1.0)(eyel_max2_out)\n",
    "eyel_cnn3_out = Conv2D(filters=384,\n",
    "                       kernel_size=3,\n",
    "                       strides=1,\n",
    "                       padding='same',\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4))(eyel_lrn2_out)\n",
    "eyel_cnn4_out = Conv2D(filters=64,\n",
    "                       kernel_size=1,\n",
    "                       strides=1,\n",
    "                       padding='valid',\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4))(eyel_cnn3_out)\n",
    "eyel_out = Flatten()(eyel_cnn4_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Right Eye Net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No Run Cell\n",
    "# in the original model both eyes share the same model, that is Eye Net\n",
    "\n",
    "eyer_input = Input(shape=(224,224,3))\n",
    "eyer_cnn1_out = Conv2D(filters=96,\n",
    "                       kernel_size=11,\n",
    "                       strides=4,\n",
    "                       padding='valid',\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4),\n",
    "                       input_shape=(224,224,3))(eyer_input)\n",
    "eyer_max1_out = MaxPool2D(pool_size=3, strides=2)(eyer_cnn1_out)\n",
    "eyer_lrn1_out = LRN2D(n=5, alpha=1e-4, beta=0.75, k=1.0)(eyer_max1_out)\n",
    "eyer_zro1_out = ZeroPadding2D(padding=2)(eyer_lrn1_out)\n",
    "eyer_cnn2_out = Conv2D(filters=256,\n",
    "                       kernel_size=5,\n",
    "                       strides=1,\n",
    "                       padding='valid',\n",
    "                       #groups=2,\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4))(eyer_zro1_out)\n",
    "eyer_max2_out = MaxPool2D(pool_size=3, strides=2)(eyer_cnn2_out)\n",
    "eyer_lrn2_out = LRN2D(n=5, alpha=1e-4, beta=0.75, k=1.0)(eyer_max2_out)\n",
    "eyer_cnn3_out = Conv2D(filters=384,\n",
    "                       kernel_size=3,\n",
    "                       strides=1,\n",
    "                       padding='same',\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4))(eyer_lrn2_out)\n",
    "eyer_cnn4_out = Conv2D(filters=64,\n",
    "                       kernel_size=1,\n",
    "                       strides=1,\n",
    "                       padding='valid',\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4))(eyer_cnn3_out)\n",
    "eyer_out = Flatten()(eyer_cnn4_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Face Net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_input = Input(shape=(224,224,3))\n",
    "face_cnn1_out = Conv2D(filters=96,\n",
    "                       kernel_size=11,\n",
    "                       strides=4,\n",
    "                       padding='valid',\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4),\n",
    "                       input_shape=(224,224,3))(face_input)\n",
    "face_max1_out = MaxPool2D(pool_size=3, strides=2)(face_cnn1_out)\n",
    "face_lrn1_out = LRN2D(n=5, alpha=1e-4, beta=0.75, k=1.0)(face_max1_out)\n",
    "face_zro1_out = ZeroPadding2D(padding=2)(face_lrn1_out)\n",
    "face_cnn2_out = Conv2D(filters=256,\n",
    "                       kernel_size=5,\n",
    "                       strides=1,\n",
    "                       padding='valid',\n",
    "                       #groups=2,\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4))(face_zro1_out)\n",
    "face_max2_out = MaxPool2D(pool_size=3, strides=2)(face_cnn2_out)\n",
    "face_lrn2_out = LRN2D(n=5, alpha=1e-4, beta=0.75, k=1.0)(face_max2_out)\n",
    "face_cnn3_out = Conv2D(filters=384,\n",
    "                       kernel_size=3,\n",
    "                       strides=1,\n",
    "                       padding='same',\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4))(face_lrn2_out)\n",
    "face_cnn4_out = Conv2D(filters=64,\n",
    "                       kernel_size=1,\n",
    "                       strides=1,\n",
    "                       padding='valid',\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4))(face_cnn3_out)\n",
    "face_flt_out = Flatten()(face_cnn4_out)\n",
    "face_dns_out = Dense(128, activation = 'relu',\n",
    "                     kernel_regularizer=regularizers.l2(1e-4))(face_flt_out)\n",
    "face_out = Dense(64, activation = 'relu')(face_dns_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Grid Net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_input = Input(shape=(25,25))\n",
    "grid_flt_out = Flatten()(grid_input)\n",
    "grid_dns_out = Dense(256, activation = 'relu',\n",
    "                     kernel_regularizer=regularizers.l2(1e-4))(grid_flt_out)\n",
    "grid_out = Dense(128, activation = 'relu',\n",
    "                 kernel_regularizer=regularizers.l2(1e-4))(grid_dns_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Merge the Eyes' Nets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_left_input = Input(shape=(224,224,3))\n",
    "eye_right_input = Input(shape=(224,224,3))\n",
    "eye_left_out = model_eye(eye_left_input)\n",
    "eye_right_out = model_eye(eye_right_input)\n",
    "\n",
    "concat_eyes = concatenate([eye_left_out, eye_right_out])\n",
    "\n",
    "eyes_out = Dense(128, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(1e-4))(concat_eyes)\n",
    "#model_eyes = Model([eye_left_input, eye_right_input], eyes_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Merge the Eyes, Face, and the Grid Nets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_all = concatenate([eyes_out, face_out, grid_out])\n",
    "\n",
    "final_dns_out = Dense(128, activation='relu',\n",
    "                      kernel_regularizer=regularizers.l2(1e-4))(concat_all)\n",
    "final_out = Dense(2, activation='relu',\n",
    "                  kernel_regularizer=regularizers.l2(1e-4))(final_dns_out)\n",
    "\n",
    "final_model = Model([eye_left_input, eye_right_input, face_input, grid_input], final_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 54, 54, 96)   34944       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 26, 26, 96)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lr_n2d_2 (LRN2D)                (None, 26, 26, 96)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 30, 30, 96)   0           lr_n2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 26, 26, 256)  614656      zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 256)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lr_n2d_3 (LRN2D)                (None, 12, 12, 256)  0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 12, 12, 384)  885120      lr_n2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 12, 12, 64)   24640       conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 25, 25)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Model)                   (None, 9216)         1559360     input_4[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 9216)         0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 625)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 18432)        0           model[1][0]                      \n",
      "                                                                 model[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          1179776     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          160256      flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          2359424     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           8256        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          32896       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 320)          0           dense_4[0][0]                    \n",
      "                                                                 dense_1[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          41088       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2)            258         dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 6,900,674\n",
      "Trainable params: 6,900,674\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_callback = LearningRateScheduler(lr_decay)\n",
    "checkpointer = ModelCheckpoint(filepath='Weights.hdf5', monitor='val_loss',\n",
    "                               verbose=1, save_best_only=True)\n",
    "base_lr = 0.0001\n",
    "momentum = 0.9\n",
    "\n",
    "sgd = SGD(lr=base_lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7995 samples, validate on 1999 samples\n",
      "Epoch 1/25\n",
      "  32/7995 [..............................] - ETA: 27:22"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "GPU sync failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-61052b981f75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m           \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m           callbacks=[lr_callback, checkpointer])\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    395\u001b[0m                       total_epochs=1)\n\u001b[0;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[1;32m--> 397\u001b[1;33m                                  prefix='val_')\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[1;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[1;34m(self, epoch, mode)\u001b[0m\n\u001b[0;32m    769\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[1;31m# Epochs only apply to `fit`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m       \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1394\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1395\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1396\u001b[1;33m     \u001b[0mlogs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   3239\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3240\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3241\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3242\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_in_graph_mode'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3243\u001b[0m     \u001b[1;31m# This is a variable which was created in an eager context, but is being\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    580\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    583\u001b[0m     raise NotImplementedError(\n\u001b[0;32m    584\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    940\u001b[0m     \"\"\"\n\u001b[0;32m    941\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    908\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: GPU sync failed"
     ]
    }
   ],
   "source": [
    "final_model.compile(optimizer=sgd, loss='mse', metrics=['mae'])\n",
    "\n",
    "final_model.fit(x=[LeftEye, RightEye, Face, GridPaper[:,:,:,0]], \n",
    "          y=labels,\n",
    "          # batch_size=256, # for the complete dataset\n",
    "          batch_size=32,\n",
    "          epochs=25,\n",
    "          # validation_data=(val_images, val_labels) # for the complete dataset  \n",
    "          validation_split=0.2,\n",
    "          shuffle=True,\n",
    "          callbacks=[lr_callback, checkpointer])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
