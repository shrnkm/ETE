{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten   \n",
    "from tensorflow.keras.layers import Layer, ZeroPadding2D, Input, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an implication of Pytorch CrossMapLRN2d with Keras\n",
    "class LRN2D(Layer):\n",
    "    \"\"\"\n",
    "    This code is adapted from pylearn2.\n",
    "    License at: https://github.com/lisa-lab/pylearn2/blob/master/LICENSE.txt\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=1e-4, k=2, beta=0.75, n=5):\n",
    "        if n % 2 == 0:\n",
    "            raise NotImplementedError('LRN2D only works with odd n. n provided: ' + str(n))\n",
    "        super(LRN2D, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.k = k\n",
    "        self.beta = beta\n",
    "        self.n = n\n",
    "\n",
    "    def get_output(self, train):\n",
    "        X = self.get_input(train)\n",
    "        b, ch, r, c = X.shape\n",
    "        half_n = self.n // 2\n",
    "        input_sqr = T.sqr(X)\n",
    "        extra_channels = T.alloc(0., b, ch + 2*half_n, r, c)\n",
    "        input_sqr = T.set_subtensor(extra_channels[:, half_n:half_n+ch, :, :], input_sqr)\n",
    "        scale = self.k\n",
    "        for i in range(self.n):\n",
    "            scale += self.alpha * input_sqr[:, i:i+ch, :, :]\n",
    "        scale = scale ** self.beta\n",
    "        return X / scale\n",
    "\n",
    "    def get_config(self):\n",
    "        return {'name': self.__class__.__name__,\n",
    "                'alpha': self.alpha,\n",
    "                'k': self.k,\n",
    "                'beta': self.beta,\n",
    "                'n': self.n}\n",
    "\n",
    "    \n",
    "\n",
    "# another implication of Pytorch CrossMapLRN2d with Keras\n",
    "class LocalResponseNormalization(Layer):\n",
    "  \n",
    "    def __init__(self, n=5, alpha=1e-4, beta=0.75, k=2, **kwargs):\n",
    "        self.n = n\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.k = k\n",
    "        super(LocalResponseNormalization, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.shape = input_shape\n",
    "        super(LocalResponseNormalization, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        _, r, c, f = self.shape \n",
    "        squared = K.square(x)\n",
    "        pooled = K.pool2d(squared, (self.n, self.n), strides=(1,1), padding='same', pool_mode='avg')\n",
    "        summed = K.sum(pooled, axis=3, keepdims=True)\n",
    "        averaged = self.alpha * K.repeat_elements(summed, f, axis=3)\n",
    "        denom = K.pow(self.k + averaged, self.beta)\n",
    "        return x / denom \n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "\n",
    "\n",
    "# Function for changing learning rate over epochs\n",
    "def lr_decay(epoch):\n",
    "    decay = .1\n",
    "    lr = base_lr * math.pow(decay, (epoch // 30))   \n",
    "    return lr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f5e35ff0d8b463c91cc3457c22ca974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load the scaled dataset\n",
    "path = 'D:/ETE/Data/Data_Mini/'\n",
    "pickles = ['LeftEye_red', 'RightEye_red', 'Face_red', 'GridMTCNN_red', 'GridPaper', 'labels']\n",
    "\n",
    "for pkl in tqdm(pickles):\n",
    "    with open(path + pkl + '.pkl','rb') as f:\n",
    "        exec(pkl + ' = pickle.load(f)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check on Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-2773e984b390>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mpkl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpickles\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'print(pkl, \\'is a\\', type('\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpkl\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;34m'), \\'with shape:\\', '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpkl\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.shape)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m9994\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pickles' is not defined"
     ]
    }
   ],
   "source": [
    "for pkl in pickles:\n",
    "    exec('print(pkl, \\'is a\\', type(' + pkl+ '), \\'with shape:\\', ' + pkl + '.shape)')\n",
    "\n",
    "idx = np.random.randint(9994)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15,45))\n",
    "for i in range(3):\n",
    "    axs[i].axis('off')\n",
    "axs[0].title.set_text('Right Eye')    \n",
    "axs[0].imshow(RightEye_red[idx])\n",
    "axs[1].title.set_text('Left Eye')\n",
    "axs[1].imshow(LeftEye_red[idx])\n",
    "axs[2].title.set_text('Face')\n",
    "axs[2].imshow(Face_red[idx])\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15,45))\n",
    "for i in range(3):\n",
    "    axs[i].set_xticks([])\n",
    "    axs[i].set_yticks([])\n",
    "axs[0].title.set_text('MTCNN Grid')\n",
    "axs[0].imshow(GridMTCNN_red[idx], cmap='gray')\n",
    "axs[1].title.set_text('Paper Grid')\n",
    "axs[1].imshow(GridPaper[idx], cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. The Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Eye Net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_input = Input(shape=(112,112,3))\n",
    "eye_cnn1_out = Conv2D(filters=96,\n",
    "                       kernel_size=11,\n",
    "                       strides=4,\n",
    "                       padding='valid',\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4),\n",
    "                       input_shape=(224,224,3))(eye_input)\n",
    "eye_max1_out = MaxPool2D(pool_size=3, strides=2)(eye_cnn1_out)\n",
    "eye_lrn1_out = LRN2D(n=5, alpha=1e-4, beta=0.75, k=1.0)(eye_max1_out)\n",
    "eye_zro1_out = ZeroPadding2D(padding=2)(eye_lrn1_out)\n",
    "eye_cnn2_out = Conv2D(filters=256,\n",
    "                      kernel_size=5,\n",
    "                      strides=1,\n",
    "                      padding='valid',\n",
    "                      #groups=2,\n",
    "                      activation='relu',\n",
    "                      kernel_regularizer=regularizers.l2(1e-4))(eye_zro1_out)\n",
    "eye_max2_out = MaxPool2D(pool_size=3, strides=2)(eye_cnn2_out)\n",
    "eye_lrn2_out = LRN2D(n=5, alpha=1e-4, beta=0.75, k=1.0)(eye_max2_out)\n",
    "eye_cnn3_out = Conv2D(filters=384,\n",
    "                      kernel_size=3,\n",
    "                      strides=1,\n",
    "                      padding='same',\n",
    "                      activation='relu',\n",
    "                      kernel_regularizer=regularizers.l2(1e-4))(eye_lrn2_out)\n",
    "eye_cnn4_out = Conv2D(filters=64,\n",
    "                      kernel_size=1,\n",
    "                      strides=1,\n",
    "                      padding='valid',\n",
    "                      activation='relu',\n",
    "                      kernel_regularizer=regularizers.l2(1e-4))(eye_cnn3_out)\n",
    "eye_out = Flatten()(eye_cnn4_out)\n",
    "\n",
    "model_eye = Model(eye_input, eye_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Left Eye Net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the original model both eyes share the same model, that is Eye Net\n",
    "eyel_input = Input(shape=(224,224,3))\n",
    "eyel_cnn1_out = Conv2D(filters=96,\n",
    "                       kernel_size=11,\n",
    "                       strides=4,\n",
    "                       padding='valid',\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4),\n",
    "                       input_shape=(224,224,3))(eyel_input)\n",
    "eyel_max1_out = MaxPool2D(pool_size=3, strides=2)(eyel_cnn1_out)\n",
    "eyel_lrn1_out = LRN2D(n=5, alpha=1e-4, beta=0.75, k=1.0)(eyel_max1_out)\n",
    "eyel_zro1_out = ZeroPadding2D(padding=2)(eyel_lrn1_out)\n",
    "eyel_cnn2_out = Conv2D(filters=256,\n",
    "                       kernel_size=5,\n",
    "                       strides=1,\n",
    "                       padding='valid',\n",
    "                       #groups=2,\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4))(eyel_zro1_out)\n",
    "eyel_max2_out = MaxPool2D(pool_size=3, strides=2)(eyel_cnn2_out)\n",
    "eyel_lrn2_out = LRN2D(n=5, alpha=1e-4, beta=0.75, k=1.0)(eyel_max2_out)\n",
    "eyel_cnn3_out = Conv2D(filters=384,\n",
    "                       kernel_size=3,\n",
    "                       strides=1,\n",
    "                       padding='same',\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4))(eyel_lrn2_out)\n",
    "eyel_cnn4_out = Conv2D(filters=64,\n",
    "                       kernel_size=1,\n",
    "                       strides=1,\n",
    "                       padding='valid',\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4))(eyel_cnn3_out)\n",
    "eyel_out = Flatten()(eyel_cnn4_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Right Eye Net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the original model both eyes share the same model, that is Eye Net\n",
    "eyer_input = Input(shape=(224,224,3))\n",
    "eyer_cnn1_out = Conv2D(filters=96,\n",
    "                       kernel_size=11,\n",
    "                       strides=4,\n",
    "                       padding='valid',\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4),\n",
    "                       input_shape=(224,224,3))(eyer_input)\n",
    "eyer_max1_out = MaxPool2D(pool_size=3, strides=2)(eyer_cnn1_out)\n",
    "eyer_lrn1_out = LRN2D(n=5, alpha=1e-4, beta=0.75, k=1.0)(eyer_max1_out)\n",
    "eyer_zro1_out = ZeroPadding2D(padding=2)(eyer_lrn1_out)\n",
    "eyer_cnn2_out = Conv2D(filters=256,\n",
    "                       kernel_size=5,\n",
    "                       strides=1,\n",
    "                       padding='valid',\n",
    "                       #groups=2,\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4))(eyer_zro1_out)\n",
    "eyer_max2_out = MaxPool2D(pool_size=3, strides=2)(eyer_cnn2_out)\n",
    "eyer_lrn2_out = LRN2D(n=5, alpha=1e-4, beta=0.75, k=1.0)(eyer_max2_out)\n",
    "eyer_cnn3_out = Conv2D(filters=384,\n",
    "                       kernel_size=3,\n",
    "                       strides=1,\n",
    "                       padding='same',\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4))(eyer_lrn2_out)\n",
    "eyer_cnn4_out = Conv2D(filters=64,\n",
    "                       kernel_size=1,\n",
    "                       strides=1,\n",
    "                       padding='valid',\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4))(eyer_cnn3_out)\n",
    "eyer_out = Flatten()(eyer_cnn4_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Face Net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_input = Input(shape=(112,112,3))\n",
    "face_cnn1_out = Conv2D(filters=96,\n",
    "                       kernel_size=11,\n",
    "                       strides=4,\n",
    "                       padding='valid',\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4),\n",
    "                       input_shape=(224,224,3))(face_input)\n",
    "face_max1_out = MaxPool2D(pool_size=3, strides=2)(face_cnn1_out)\n",
    "face_lrn1_out = LRN2D(n=5, alpha=1e-4, beta=0.75, k=1.0)(face_max1_out)\n",
    "face_zro1_out = ZeroPadding2D(padding=2)(face_lrn1_out)\n",
    "face_cnn2_out = Conv2D(filters=256,\n",
    "                       kernel_size=5,\n",
    "                       strides=1,\n",
    "                       padding='valid',\n",
    "                       #groups=2,\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4))(face_zro1_out)\n",
    "face_max2_out = MaxPool2D(pool_size=3, strides=2)(face_cnn2_out)\n",
    "face_lrn2_out = LRN2D(n=5, alpha=1e-4, beta=0.75, k=1.0)(face_max2_out)\n",
    "face_cnn3_out = Conv2D(filters=384,\n",
    "                       kernel_size=3,\n",
    "                       strides=1,\n",
    "                       padding='same',\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4))(face_lrn2_out)\n",
    "face_cnn4_out = Conv2D(filters=64,\n",
    "                       kernel_size=1,\n",
    "                       strides=1,\n",
    "                       padding='valid',\n",
    "                       activation='relu',\n",
    "                       kernel_regularizer=regularizers.l2(1e-4))(face_cnn3_out)\n",
    "face_flt_out = Flatten()(face_cnn4_out)\n",
    "face_dns_out = Dense(128, activation = 'relu',\n",
    "                     kernel_regularizer=regularizers.l2(1e-4))(face_flt_out)\n",
    "face_out = Dense(64, activation = 'relu')(face_dns_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Papaer Grid Net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_input = Input(shape=(25,25))\n",
    "grid_flt_out = Flatten()(grid_input)\n",
    "grid_dns_out = Dense(256, activation = 'relu',\n",
    "                     kernel_regularizer=regularizers.l2(1e-4))(grid_flt_out)\n",
    "grid_out = Dense(128, activation = 'relu',\n",
    "                 kernel_regularizer=regularizers.l2(1e-4))(grid_dns_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **MTCNN Grid Net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_input = Input(shape=(25,25))\n",
    "grid_flt_out = Flatten()(grid_input)\n",
    "grid_dns_out = Dense(256, activation = 'relu',\n",
    "                     kernel_regularizer=regularizers.l2(1e-4))(grid_flt_out)\n",
    "grid_out = Dense(128, activation = 'relu',\n",
    "                 kernel_regularizer=regularizers.l2(1e-4))(grid_dns_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Merge the Eyes' Nets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eye_left_input = Input(shape=(224,224,3)) # for the original dataset\n",
    "# eye_right_input = Input(shape=(224,224,3)) # for the original dataset\n",
    "eye_left_input = Input(shape=(112,112,3)) # for the half-sized scaled dataset\n",
    "eye_right_input = Input(shape=(112,112,3)) # for the half-sized scaled dataset\n",
    "eye_left_out = model_eye(eye_left_input)\n",
    "eye_right_out = model_eye(eye_right_input)\n",
    "\n",
    "concat_eyes = concatenate([eye_left_out, eye_right_out])\n",
    "\n",
    "eyes_out = Dense(128, activation='relu',\n",
    "                 kernel_regularizer=regularizers.l2(1e-4))(concat_eyes)\n",
    "#model_eyes = Model([eye_left_input, eye_right_input], eyes_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Merge the Eyes, Face, and the Grid Nets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_all = concatenate([eyes_out, face_out, grid_out])\n",
    "\n",
    "final_dns_out = Dense(128, activation='relu',\n",
    "                      kernel_regularizer=regularizers.l2(1e-4))(concat_all)\n",
    "final_out = Dense(2, activation='relu',\n",
    "                  kernel_regularizer=regularizers.l2(1e-4))(final_dns_out)\n",
    "\n",
    "final_model = Model([eye_left_input, eye_right_input, face_input, grid_input], final_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 112, 112, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 26, 26, 96)   34944       input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 96)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lr_n2d_2 (LRN2D)                (None, 12, 12, 96)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 16, 16, 96)   0           lr_n2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 12, 12, 256)  614656      zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 256)    0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lr_n2d_3 (LRN2D)                (None, 5, 5, 256)    0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 5, 5, 384)    885120      lr_n2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 112, 112, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 112, 112, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 5, 5, 64)     24640       conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 25, 25)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Model)                   (None, 1600)         1559360     input_5[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1600)         0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 625)          0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 3200)         0           model[1][0]                      \n",
      "                                                                 model[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          204928      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          160256      flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          409728      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           8256        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          32896       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 320)          0           dense_4[0][0]                    \n",
      "                                                                 dense_1[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          41088       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2)            258         dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,976,130\n",
      "Trainable params: 3,976,130\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_callback = LearningRateScheduler(lr_decay)\n",
    "checkpointer = ModelCheckpoint(filepath='Weights.hdf5', monitor='val_loss',\n",
    "                               verbose=1, save_best_only=True)\n",
    "base_lr = 0.0001\n",
    "momentum = 0.9\n",
    "\n",
    "sgd = SGD(lr=base_lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7995 samples, validate on 1999 samples\n",
      "Epoch 1/25\n",
      "7968/7995 [============================>.] - ETA: 0s - loss: 210.1814 - mae: 4.6523\n",
      "Epoch 00001: val_loss improved from inf to 92.11571, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 13s 2ms/sample - loss: 209.7634 - mae: 4.6480 - val_loss: 92.1157 - val_mae: 3.9598\n",
      "Epoch 2/25\n",
      "7968/7995 [============================>.] - ETA: 0s - loss: 93.6004 - mae: 4.0538\n",
      "Epoch 00002: val_loss improved from 92.11571 to 92.10929, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 10s 1ms/sample - loss: 93.5817 - mae: 4.0527 - val_loss: 92.1093 - val_mae: 3.9598\n",
      "Epoch 3/25\n",
      "7968/7995 [============================>.] - ETA: 0s - loss: 93.5778 - mae: 4.0530\n",
      "Epoch 00003: val_loss improved from 92.10929 to 92.10287, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 9s 1ms/sample - loss: 93.5752 - mae: 4.0527 - val_loss: 92.1029 - val_mae: 3.9598\n",
      "Epoch 4/25\n",
      "7968/7995 [============================>.] - ETA: 0s - loss: 93.5616 - mae: 4.0520\n",
      "Epoch 00004: val_loss improved from 92.10287 to 92.09646, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 10s 1ms/sample - loss: 93.5688 - mae: 4.0527 - val_loss: 92.0965 - val_mae: 3.9598\n",
      "Epoch 5/25\n",
      "7968/7995 [============================>.] - ETA: 0s - loss: 93.5759 - mae: 4.0531\n",
      "Epoch 00005: val_loss improved from 92.09646 to 92.09005, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 9s 1ms/sample - loss: 93.5624 - mae: 4.0527 - val_loss: 92.0901 - val_mae: 3.9598\n",
      "Epoch 6/25\n",
      "7968/7995 [============================>.] - ETA: 0s - loss: 93.5771 - mae: 4.0542 ETA: 0s\n",
      "Epoch 00006: val_loss improved from 92.09005 to 92.08364, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 9s 1ms/sample - loss: 93.5560 - mae: 4.0527 - val_loss: 92.0836 - val_mae: 3.9598\n",
      "Epoch 7/25\n",
      "7968/7995 [============================>.] - ETA: 0s - loss: 93.5446 - mae: 4.0529\n",
      "Epoch 00007: val_loss improved from 92.08364 to 92.07723, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 9s 1ms/sample - loss: 93.5496 - mae: 4.0527 - val_loss: 92.0772 - val_mae: 3.9598\n",
      "Epoch 8/25\n",
      "7968/7995 [============================>.] - ETA: 0s - loss: 93.5521 - mae: 4.0527\n",
      "Epoch 00008: val_loss improved from 92.07723 to 92.07082, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 9s 1ms/sample - loss: 93.5432 - mae: 4.0527 - val_loss: 92.0708 - val_mae: 3.9598\n",
      "Epoch 9/25\n",
      "7968/7995 [============================>.] - ETA: 0s - loss: 93.5515 - mae: 4.0539 ETA: 0s - loss: 93.5471 -\n",
      "Epoch 00009: val_loss improved from 92.07082 to 92.06441, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 9s 1ms/sample - loss: 93.5368 - mae: 4.0527 - val_loss: 92.0644 - val_mae: 3.9598\n",
      "Epoch 10/25\n",
      "7968/7995 [============================>.] - ETA: 0s - loss: 93.5648 - mae: 4.0549 ETA: 0s - loss: 93.4964 - mae: \n",
      "Epoch 00010: val_loss improved from 92.06441 to 92.05800, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 10s 1ms/sample - loss: 93.5304 - mae: 4.0527 - val_loss: 92.0580 - val_mae: 3.9598\n",
      "Epoch 11/25\n",
      "7968/7995 [============================>.] - ETA: 0s - loss: 93.5286 - mae: 4.0525\n",
      "Epoch 00011: val_loss improved from 92.05800 to 92.05159, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 10s 1ms/sample - loss: 93.5240 - mae: 4.0527 - val_loss: 92.0516 - val_mae: 3.9598\n",
      "Epoch 12/25\n",
      "7968/7995 [============================>.] - ETA: 0s - loss: 93.5248 - mae: 4.0528\n",
      "Epoch 00012: val_loss improved from 92.05159 to 92.04518, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 10s 1ms/sample - loss: 93.5175 - mae: 4.0527 - val_loss: 92.0452 - val_mae: 3.9598\n",
      "Epoch 13/25\n",
      "7968/7995 [============================>.] - ETA: 0s - loss: 93.4358 - mae: 4.0485 ETA: \n",
      "Epoch 00013: val_loss improved from 92.04518 to 92.03878, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 9s 1ms/sample - loss: 93.5111 - mae: 4.0527 - val_loss: 92.0388 - val_mae: 3.9598\n",
      "Epoch 14/25\n",
      "7968/7995 [============================>.] - ETA: 0s - loss: 93.5567 - mae: 4.0567\n",
      "Epoch 00014: val_loss improved from 92.03878 to 92.03238, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 10s 1ms/sample - loss: 93.5047 - mae: 4.0527 - val_loss: 92.0324 - val_mae: 3.9598\n",
      "Epoch 15/25\n",
      "7968/7995 [============================>.] - ETA: 0s - loss: 93.5359 - mae: 4.0552 ETA: 0s - loss: 93.5102 - mae: 4.\n",
      "Epoch 00015: val_loss improved from 92.03238 to 92.02597, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 9s 1ms/sample - loss: 93.4983 - mae: 4.0527 - val_loss: 92.0260 - val_mae: 3.9598\n",
      "Epoch 16/25\n",
      "7968/7995 [============================>.] - ETA: 0s - loss: 93.5248 - mae: 4.0554\n",
      "Epoch 00016: val_loss improved from 92.02597 to 92.01956, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 10s 1ms/sample - loss: 93.4919 - mae: 4.0527 - val_loss: 92.0196 - val_mae: 3.9598\n",
      "Epoch 17/25\n",
      "7968/7995 [============================>.] - ETA: 0s - loss: 93.4314 - mae: 4.0492\n",
      "Epoch 00017: val_loss improved from 92.01956 to 92.01316, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 10s 1ms/sample - loss: 93.4855 - mae: 4.0527 - val_loss: 92.0132 - val_mae: 3.9598\n",
      "Epoch 18/25\n",
      "7968/7995 [============================>.] - ETA: 0s - loss: 93.4326 - mae: 4.0514\n",
      "Epoch 00018: val_loss improved from 92.01316 to 92.00676, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 9s 1ms/sample - loss: 93.4791 - mae: 4.0527 - val_loss: 92.0068 - val_mae: 3.9598\n",
      "Epoch 19/25\n",
      "7968/7995 [============================>.] - ETA: 0s - loss: 93.4756 - mae: 4.0543\n",
      "Epoch 00019: val_loss improved from 92.00676 to 92.00036, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 9s 1ms/sample - loss: 93.4727 - mae: 4.0527 - val_loss: 92.0004 - val_mae: 3.9598\n",
      "Epoch 20/25\n",
      "7968/7995 [============================>.] - ETA: 0s - loss: 93.4704 - mae: 4.0535\n",
      "Epoch 00020: val_loss improved from 92.00036 to 91.99395, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 9s 1ms/sample - loss: 93.4663 - mae: 4.0527 - val_loss: 91.9940 - val_mae: 3.9598\n",
      "Epoch 21/25\n",
      "7968/7995 [============================>.] - ETA: 0s - loss: 93.4324 - mae: 4.0516\n",
      "Epoch 00021: val_loss improved from 91.99395 to 91.98756, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 9s 1ms/sample - loss: 93.4599 - mae: 4.0527 - val_loss: 91.9876 - val_mae: 3.9598\n",
      "Epoch 22/25\n",
      "7968/7995 [============================>.] - ETA: 0s - loss: 93.4726 - mae: 4.0547\n",
      "Epoch 00022: val_loss improved from 91.98756 to 91.98116, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 9s 1ms/sample - loss: 93.4535 - mae: 4.0527 - val_loss: 91.9812 - val_mae: 3.9598\n",
      "Epoch 23/25\n",
      "7968/7995 [============================>.] - ETA: 0s - loss: 93.4083 - mae: 4.0504\n",
      "Epoch 00023: val_loss improved from 91.98116 to 91.97475, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 10s 1ms/sample - loss: 93.4471 - mae: 4.0527 - val_loss: 91.9748 - val_mae: 3.9598\n",
      "Epoch 24/25\n",
      "7968/7995 [============================>.] - ETA: 0s - loss: 93.4733 - mae: 4.0547\n",
      "Epoch 00024: val_loss improved from 91.97475 to 91.96835, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 10s 1ms/sample - loss: 93.4407 - mae: 4.0527 - val_loss: 91.9684 - val_mae: 3.9598\n",
      "Epoch 25/25\n",
      "7968/7995 [============================>.] - ETA: 0s - loss: 93.4632 - mae: 4.0553\n",
      "Epoch 00025: val_loss improved from 91.96835 to 91.96196, saving model to Weights.hdf5\n",
      "7995/7995 [==============================] - 10s 1ms/sample - loss: 93.4343 - mae: 4.0527 - val_loss: 91.9620 - val_mae: 3.9598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2d46c29c648>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.compile(optimizer=sgd, loss='mse', metrics=['mae'])\n",
    "\n",
    "final_model.fit(x=[LeftEye_red, RightEye_red, Face_red, GridPaper], \n",
    "          y=labels,\n",
    "          # batch_size=256, # for the complete dataset\n",
    "          batch_size=32,\n",
    "          epochs=25,\n",
    "          # validation_data=(val_images, val_labels) # for the complete dataset  \n",
    "          validation_split=0.2,\n",
    "          shuffle=True,\n",
    "          callbacks=[lr_callback, checkpointer])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
