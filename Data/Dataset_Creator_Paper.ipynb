{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Lists of Train, Test, and Val Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " We have 1271 train folders/subjects, containing 1251983 frames/samples\n",
      " and 50 validate folders/subjects, containing 59480 frames/samples\n",
      " and 150 test folders/subjects, containing 179496 frames/samples.\n"
     ]
    }
   ],
   "source": [
    "# make a list of the folders in the data directory\n",
    "folders = [name for name in os.listdir('Data_MIT/')]\n",
    "# drop the irrelevant file in the data directory\n",
    "folders.remove('LICENSE.md')\n",
    "\n",
    "# create three lists for recording the training, testing, and\n",
    "# validating frames (folders)\n",
    "train =[]\n",
    "val = []\n",
    "test = []\n",
    "\n",
    "\n",
    "# create three counters for counting the number of frames/samples per set\n",
    "train_sp = 0\n",
    "val_sp = 0\n",
    "test_sp = 0\n",
    "\n",
    "# loop over all folders available in the folders list\n",
    "for folder in folders:\n",
    "    # set the path to the folder on my system\n",
    "    path = 'Data_MIT/' + folder\n",
    "    #  read the info jason\n",
    "    with open(path + '/info.json', 'r') as file:\n",
    "        info = json.load(file)\n",
    "    # if there is at least one useable frame in the folder,\n",
    "    if info['NumFaceDetections'] and info['NumEyeDetections']:\n",
    "        # read the whether it is a train, test, or validation folder\n",
    "        subset = info['Dataset']\n",
    "        # and append the name of the folder to the corresponding list\n",
    "        exec(subset + '.append(str(folder))')\n",
    "        # and also add the number of useable/valid frames avaible in the folder\n",
    "        # to the corresponding counter\n",
    "        exec(subset + '_sp += min(info[\\'NumFaceDetections\\'], info[\\'NumEyeDetections\\'])')\n",
    "\n",
    "# check the number of folders/subjects in each set\n",
    "train_sb = len(train)\n",
    "val_sb = len(val)\n",
    "test_sb = len(test)\n",
    "\n",
    "# print it out\n",
    "print(' We have', train_sb, 'train folders/subjects, containing',\n",
    "      train_sp, 'frames/samples\\n and',\n",
    "      val_sb, 'validate folders/subjects, containing',\n",
    "      val_sp, 'frames/samples\\n and',\n",
    "      test_sb, 'test folders/subjects, containing',\n",
    "      test_sp, 'frames/samples.')\n",
    "\n",
    "with open('train.pkl', 'wb') as f:\n",
    "    pickle.dump(train, f)\n",
    "\n",
    "with open('val.pkl', 'wb') as f:\n",
    "    pickle.dump(val, f)\n",
    "    \n",
    "with open('test.pkl', 'wb') as f:\n",
    "    pickle.dump(test, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Random Folders and Creat a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually set the size of test, train, and validation sets (by samples)\n",
    "\n",
    "train_size = 10000 # must be less than 1251983\n",
    "val_size = 1000 # must be less than 179496\n",
    "test_size = 2000 # must be less than 59480\n",
    "\n",
    "DPI = 96 # resolution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to read one frame/image,\n",
    "# and return \n",
    "\n",
    "def read_file(file, coords, idx, dataset):\n",
    "    '''\n",
    "    The function takes the file (string), and the\n",
    "    coordinates info (np.array), and the target dataset\n",
    "    (string='train'/'val'/'test'), and will save 4 images:\n",
    "    face, left eye, right eye patches, and the face grid,\n",
    "    under the 'idx' name (integer), in the target dataset\n",
    "    and also 4 positional float values will be appended\n",
    "    to the label an np.array in the same dataset.\n",
    "    '''\n",
    "    \n",
    "    # read the image file\n",
    "    img = cv2.cvtColor(cv2.imread(file), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # ----------------------------------------------------------------\n",
    "    # first we have to check to make sure the stupid face bounding box\n",
    "    # does not fall out of the frame\n",
    "    # ----------------------------------------------------------------\n",
    "    # 1. X is negative\n",
    "    if coords[0] < 0:\n",
    "        # so we fill the shortage by replicating the edge \n",
    "        img = cv2.copyMakeBorder(img, 0, 0, np.abs(coords[0]), 0, cv2.BORDER_REPLICATE)\n",
    "        # and reset the X value regarding the new frame\n",
    "        coords[0] = 0\n",
    "\n",
    "    # 2. Y is negative\n",
    "    if coords[1] < 0:\n",
    "        # so we fill the shortage by replicating the edge \n",
    "        img = cv2.copyMakeBorder(img, np.abs(coords[1]), 0, 0, 0, cv2.BORDER_REPLICATE)\n",
    "        # and reset the Y value regarding the new frame\n",
    "        coords[1] = 0\n",
    "\n",
    "    # 3. X+W is larger than the frame width\n",
    "    if (coords[0]+coords[2]) > img.shape[1]:\n",
    "        # so we fill the shortage (diff) by replicating the edge\n",
    "        diff = np.abs(img.shape[1]-(coords[0]+coords[2]))\n",
    "        img = cv2.copyMakeBorder(img, 0, 0, 0, diff, cv2.BORDER_REPLICATE)\n",
    "\n",
    "    # 4. Y+H is larger than the frame height\n",
    "    if (coords[1]+coords[3]) > img.shape[0]:\n",
    "        # so we fill the shortage (diff) by replicating the edge\n",
    "        diff = np.abs(img.shape[0]-(coords[1]+coords[3]))\n",
    "        img = cv2.copyMakeBorder(img, 0, diff, 0, 0, 0, cv2.BORDER_REPLICATE)\n",
    "    # ----------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    # ----------------------------------------------------------------\n",
    "    # save the face patch\n",
    "    # ----------------------------------------------------------------\n",
    "    crop = img[coords[1]:coords[1]+coords[3],\n",
    "               coords[0]:coords[0]+coords[2]]\n",
    "    # set the path-name\n",
    "    path = dataset + '/face/' + idx + '.png'\n",
    "\n",
    "    fig = plt.figure(figsize=(crop.shape[0]/DPI,crop.shape[1]/DPI), dpi=DPI)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(crop)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, pad_inches=0.0, dpi=DPI)\n",
    "    plt.close(fig);\n",
    "    # ----------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    # ----------------------------------------------------------------\n",
    "    # save the left eye patch\n",
    "    # ----------------------------------------------------------------\n",
    "    eyel = crop[coords[5]:coords[5]+coords[7],\n",
    "                coords[4]:coords[4]+coords[6]]\n",
    "    # set the path-name\n",
    "    path = dataset + '/eyel/' + idx + '.png'\n",
    "\n",
    "    fig = plt.figure(figsize=(eyel.shape[0]/DPI,eyel.shape[1]/DPI), dpi=DPI)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(eyel)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, pad_inches=0.0, dpi=DPI)\n",
    "    plt.close(fig);\n",
    "    # ----------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    # ----------------------------------------------------------------\n",
    "    # save the right eye patch\n",
    "    # ----------------------------------------------------------------\n",
    "    eyer = crop[coords[9]:coords[9]+coords[11],\n",
    "                coords[8]:coords[8]+coords[10]]\n",
    "    # set the path-name\n",
    "    path = dataset + '/eyer/' + idx + '.png'\n",
    "\n",
    "    fig = plt.figure(figsize=(eyer.shape[0]/DPI,eyer.shape[1]/DPI), dpi=DPI)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(eyer)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, pad_inches=0.0, dpi=DPI)\n",
    "    plt.close(fig);\n",
    "    # ----------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    # ----------------------------------------------------------------\n",
    "    # save the face grid\n",
    "    # ----------------------------------------------------------------\n",
    "    fig, ax = plt.subplots(figsize=(25/DPI,25/DPI), dpi=DPI)\n",
    "    # set the white canvas\n",
    "    canvas = np.zeros((25,25))\n",
    "    \n",
    "    # set the black face grid\n",
    "    the_grid = patches.Rectangle((coords[12],25-coords[13]-coords[15]),\n",
    "                                 coords[14],coords[15],\n",
    "                                 linewidth=0,facecolor='black')\n",
    "    # set the path-name\n",
    "    path = dataset + '/grid/' + idx + '.png'\n",
    "\n",
    "    ax.add_patch(the_grid)\n",
    "    plt.axis('off')\n",
    "    ax.imshow(canvas, extent=[0,25,0,25], cmap='Greys')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, pad_inches=0.0, dpi=DPI)\n",
    "    plt.close(fig);\n",
    "    # ----------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    # ----------------------------------------------------------------\n",
    "    # append the labels grid\n",
    "    # ----------------------------------------------------------------\n",
    "    label = np.array([[coords[16], coords[17], coords[18], coords[19]]])\n",
    "    exec(dataset + '_labels = np.append(' + dataset + '_labels, label, axis=0)')\n",
    "    # ----------------------------------------------------------------\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to read a set-list, pick random folders,\n",
    "# and add the folder's valid frames to dataset\n",
    "\n",
    "def read_folder(folder, samples, dataset):\n",
    "    '''\n",
    "    The function takes the name of the target folder (string),\n",
    "    the samples (integer) which is the number of needed samples\n",
    "    before the target set gets full, and\n",
    "    the target dataset (string='train'/'val'/'test'), and\n",
    "    will add the desired number of samples (4 images: face, left eye,\n",
    "    right eye patches, and the face grid, 4 positional float values\n",
    "    in the form an np.array to the labels array) to the target set.\n",
    "    '''\n",
    "    # set the path to the target folder\n",
    "    path = 'Data_MIT/' + folder\n",
    "    \n",
    "    \n",
    "    # ----------------------------------------------------------------\n",
    "    # reading the json files\n",
    "    # ----------------------------------------------------------------\n",
    "    # Face Crop\n",
    "    with open(path + '/appleFace.json', 'r') as file:\n",
    "        face = json.load(file)\n",
    "    \n",
    "    # Left Eye\n",
    "    with open(path + '/appleLeftEye.json', 'r') as file:\n",
    "        eye_l = json.load(file)\n",
    "\n",
    "    # Right Eye\n",
    "    with open(path + '/appleRightEye.json', 'r') as file:\n",
    "        eye_r = json.load(file)\n",
    "\n",
    "    # Face Grid\n",
    "    with open(path + '/faceGrid.json', 'r') as file:\n",
    "        grid = json.load(file)\n",
    "\n",
    "    # dot\n",
    "    with open(path + '/dotInfo.json', 'r') as file:\n",
    "        dot = json.load(file)\n",
    "    # ----------------------------------------------------------------\n",
    "    \n",
    "        \n",
    "    \n",
    "    # ----------------------------------------------------------------\n",
    "    # make a list of indices of the invalid Frames in the Folder,\n",
    "    # check if the requested number of samples if greater than the\n",
    "    # number of valid frames in the folder, take the min value and\n",
    "    # randomly pick 'min' number of samples\n",
    "    # ----------------------------------------------------------------\n",
    "    *******************************************************************\n",
    "    there's a huge problem here. you are taking the union, while you\n",
    "    should have taken the intersection\n",
    "    *******************************************************************\n",
    "    indices = [i for i, x in enumerate(face['IsValid']) if x == 1]\n",
    "    indices += [i for i, x in enumerate(eye_l['IsValid']) if x == 1]\n",
    "    indices += [i for i, x in enumerate(eye_r['IsValid']) if x == 1]\n",
    "    indices += [i for i, x in enumerate(grid['IsValid']) if x == 1]\n",
    "\n",
    "    indices = list(set(indices))\n",
    "    \n",
    "    pick = min(samples, len(indices))\n",
    "    \n",
    "    idx = random.sample(indices, k=pick)\n",
    "    # ----------------------------------------------------------------\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ----------------------------------------------------------------\n",
    "    # iterate over the indices in idx list, read images and save data\n",
    "    # ----------------------------------------------------------------\n",
    "    for ind in idx:\n",
    "        path_frames = 'Data_MIT/' + folder + '/frames/'\n",
    "        files = [name for name in os.listdir(path)]\n",
    "        \n",
    "        # set the path to the target folder\n",
    "        path = 'Data_MIT/' + folder + '/frames/' + file_name\n",
    "        \n",
    "        coords = np.array([round(face['X'][idx]), round(face['Y'][idx]),  #0-1\n",
    "                           round(face['W'][idx]), round(face['H'][idx]),  #2-3\n",
    "                           round(eye_l['X'][idx]), round(eye_l['Y'][idx]),#4-5\n",
    "                           round(eye_l['W'][idx]), round(eye_l['H'][idx]),#6-7\n",
    "                           round(eye_r['X'][idx]), round(eye_r['Y'][idx]),#8-9\n",
    "                           round(eye_r['W'][idx]), round(eye_r['H'][idx]),#10-11\n",
    "                           round(grid['X'][idx]), round(grid['Y'][idx]),  #12-13\n",
    "                           round(grid['W'][idx]), round(grid['H'][idx]),  #14-15\n",
    "                           dot['XPts'][idx], dot['YPts'][idx],            #16-17\n",
    "                           dot['XCam'][idx], dot['YCam'][idx]])           #18-19\n",
    "\n",
    "    # ----------------------------------------------------------------\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ----------------------------------------------------------------\n",
    "    # randomly pick 'min' number of samples\n",
    "    # ----------------------------------------------------------------\n",
    "    # ----------------------------------------------------------------\n",
    "    \n",
    "\n",
    "\n",
    "# set the path to save the images in the test folder\n",
    "path_test = 'test/' + str(folder) + '_' + str(idx) + '.pkl'\n",
    "\n",
    "# save the array in a pickle file\n",
    "with open(path_test,'wb') as f:\n",
    "    pickle.dump(label, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
