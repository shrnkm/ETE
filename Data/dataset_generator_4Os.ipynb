{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import statistics\n",
    "import cv2\n",
    "import json\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle, Polygon\n",
    "from tqdm.notebook import tqdm\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# function for reading the Json files\n",
    "# ----------------------------------------------------------------------\n",
    "def idx_finder(folder, orientation):\n",
    "    '''\n",
    "    This function takes the folder name (string),\n",
    "    and an orientation adn returns a list of indices\n",
    "    of the target orientation and valid frames in\n",
    "    the folder.\n",
    "    '''\n",
    "    # set the specific folder's path\n",
    "    path = 'Data_MIT/' + folder\n",
    "\n",
    "    # read the json files\n",
    "    # ------------------------------------------------------------------\n",
    "    # read the Face Crop json\n",
    "    with open(path + '/appleFace.json', 'r') as file:\n",
    "        face = json.load(file)\n",
    "    # read the Left Eye json\n",
    "    with open(path + '/appleLeftEye.json', 'r') as file:\n",
    "        eye_l = json.load(file)\n",
    "    # read the Right Eye json\n",
    "    with open(path + '/appleRightEye.json', 'r') as file:\n",
    "        eye_r = json.load(file)\n",
    "    # read the Scree json\n",
    "    with open(path + '/screen.json', 'r') as file:\n",
    "        screen = json.load(file)\n",
    "    \n",
    "    # make a list of all valid indices\n",
    "    # ------------------------------------------------------------------\n",
    "    # list of all frames with full face in it\n",
    "    faces = [idx for idx, val in enumerate(face['IsValid']) if val == 1]\n",
    "    # list of all frames with the left eye in it\n",
    "    eyes_l = [idx for idx, val in enumerate(eye_l['IsValid']) if val == 1]\n",
    "    # list of all frames with the right eye in it\n",
    "    eyes_r = [idx for idx, val in enumerate(eye_r['IsValid']) if val == 1]\n",
    "    # list of all frames with the desired orientation\n",
    "    oriented = [idx for idx, ori in enumerate(screen['Orientation']) if ori == orientation]\n",
    "    # intersection of all those lists\n",
    "    indices = [idx for idx in faces if idx in eyes_l and idx in eyes_r and idx in oriented]\n",
    "    \n",
    "    return indices\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# a function for reading Json files\n",
    "# ----------------------------------------------------------------------\n",
    "def json_reader(dictionary, jsn, frame):\n",
    "    '''\n",
    "    The function takes a dictionary and a string mentioning\n",
    "    the name of the json file, and a frame index, and it\n",
    "    reads index-related info from json files and record them\n",
    "    in the dictionary.\n",
    "    '''\n",
    "    # set the path to the json files\n",
    "    path = 'Data_MIT/' + frame[:5] + '/'\n",
    "    # get the index of the frame\n",
    "    idx = int(frame[-5:])\n",
    "    # read the face json file\n",
    "    with open(str(path + 'apple' + jsn + '.json'), 'r') as file:\n",
    "        jsn_info = json.load(file)    \n",
    "    # add the face patch coordinates to the dictionary\n",
    "    dictionary[jsn] = [round(jsn_info['X'][idx]),\n",
    "                       round(jsn_info['Y'][idx]),\n",
    "                       round(jsn_info['W'][idx]),\n",
    "                       round(jsn_info['H'][idx])]\n",
    "\n",
    "\n",
    "    \n",
    "# ----------------------------------------------------------------------    \n",
    "# a function to cut, resize, and save a patch\n",
    "# ----------------------------------------------------------------------\n",
    "def patch_reader(image, coordinates, path):\n",
    "    '''\n",
    "    The function takes an image and a list of coordinates (int),\n",
    "    and a path (string), and cuts a patch out of the image,\n",
    "    resizes it, and saves it in desired path.\n",
    "    '''\n",
    "    # check if the patches falls out of the frame\n",
    "    # -------------------------------------------\n",
    "    # whether the X coordinate is negative\n",
    "    if coordinates[0] < 0:\n",
    "        # if so, fill the shortage by replicating the edge \n",
    "        image = cv2.copyMakeBorder(image, 0, 0, np.abs(coordinates[0]), 0, cv2.BORDER_REPLICATE)\n",
    "        # and reset the X value regarding the new frame\n",
    "        coordinates[0] = 0\n",
    "\n",
    "    # whether Y is negative\n",
    "    if coordinates[1] < 0:\n",
    "        # if so, fill the shortage by replicating the edge \n",
    "        image = cv2.copyMakeBorder(image, np.abs(coordinates[1]), 0, 0, 0, cv2.BORDER_REPLICATE)\n",
    "        # and reset the Y value regarding the new frame\n",
    "        coordinates[1] = 0\n",
    "\n",
    "    # whether X+W is larger than the frame width\n",
    "    if coordinates[0]+coordinates[2] > image.shape[1]:\n",
    "        # if so, fill the shortage (diff) by replicating the edge\n",
    "        diff = np.abs(image.shape[1]-(coordinates[0]+coordinates[2]))\n",
    "        image = cv2.copyMakeBorder(image, 0, 0, 0, diff, cv2.BORDER_REPLICATE)\n",
    "\n",
    "    # whether Y+H is larger than the frame height\n",
    "    if coordinates[1]+coordinates[3] > image.shape[0]:\n",
    "        # so we fill the shortage (diff) by replicating the edge\n",
    "        diff = np.abs(image.shape[0]-(coordinates[1]+coordinates[3]))\n",
    "        image = cv2.copyMakeBorder(image, 0, diff, 0, 0, 0, cv2.BORDER_REPLICATE)\n",
    "\n",
    "        \n",
    "    # cut the patch\n",
    "    patch = image[coordinates[1]:coordinates[1]+coordinates[3],\n",
    "                  coordinates[0]:coordinates[0]+coordinates[2]]\n",
    "    \n",
    "    # resize the patch\n",
    "    patch_res = cv2.resize(patch, (64, 64))\n",
    "    \n",
    "    # save the image\n",
    "    cv2.imwrite(path, patch_res);\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# a function for reading grid coordinates\n",
    "# ----------------------------------------------------------------------\n",
    "def get_coords(folder, frame):\n",
    "    '''\n",
    "    This function takes the folder and the frame names (string),\n",
    "    read the faceGrid.json file, and returns the grid\n",
    "    coordinates.\n",
    "    '''\n",
    "    # set the path to the grid json file\n",
    "    path = 'Data_MIT/' + folder + '/faceGrid.json'\n",
    "    # read the json file\n",
    "    with open(path, 'r') as file:\n",
    "        grid = json.load(file)\n",
    "    # set the frame index\n",
    "    idx = int(frame)\n",
    "    # make a list of the X,Y,W, and H coordinates\n",
    "    coords = [round(grid['X'][idx]), round(grid['Y'][idx]),\n",
    "              round(grid['W'][idx]), round(grid['H'][idx])]\n",
    "    \n",
    "    # and return the coords list\n",
    "    return coords\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# a function for creating the grids based on the paper\n",
    "# ----------------------------------------------------------------------\n",
    "def grid_paper(coords, name):\n",
    "    '''\n",
    "    This function takes a list of coordinates, and\n",
    "    a name, and saves the face grid within a 25X25\n",
    "    white frame. \n",
    "    '''\n",
    "    # set the canvas\n",
    "    canvas = np.ones((25,25))*255\n",
    "\n",
    "    # grid coordinates\n",
    "    x = coords[0]\n",
    "    y = coords[1]\n",
    "    w = coords[2]\n",
    "    h = coords[3]\n",
    "    \n",
    "    # mask the face location\n",
    "    canvas[y:y+h, x:x+w] = 0\n",
    "\n",
    "    # set the path to save the grids\n",
    "    path = 'Data_Mini_4Os/grid_paper/' + name + '.jpg'\n",
    "    # save the face grid\n",
    "    plt.imsave(path, canvas, cmap='gray');\n",
    "    \n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# a function for converting color pathes to grayscale\n",
    "# ----------------------------------------------------------------------\n",
    "def gray(path_read, path_write):\n",
    "    '''\n",
    "    The function takes a path to a folder\n",
    "    (path_read: string), read images in the folder,\n",
    "    convert them to grayscale versions, and save\n",
    "    them in another folder (path_write: string)\n",
    "    '''\n",
    "    # make a list of the images in the folder\n",
    "    images = [name for name in os.listdir(path_read)]\n",
    "    \n",
    "    # for each image\n",
    "    for image in images:\n",
    "        # set the path to the color image\n",
    "        read = path_read + image\n",
    "        # read the image\n",
    "        image_color = cv2.imread(read)\n",
    "        # generate the grayscale version of the image\n",
    "        image_gray = cv2.cvtColor(image_color, cv2.COLOR_BGR2GRAY)\n",
    "        # set the path for writing grayscale image\n",
    "        write = path_write + image\n",
    "        # and save the grayscale image\n",
    "        cv2.imwrite(write, image_gray)\n",
    "    \n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# a function for reading images and saving them as pickle files\n",
    "# ----------------------------------------------------------------------\n",
    "def pickle_write(path, name):\n",
    "    '''\n",
    "    The function takes a path to a folder\n",
    "    (string), read images in that folder,\n",
    "    turns them all to one np.array, and saves\n",
    "    it as a pickle file under the give 'name'.\n",
    "    '''\n",
    "    # create an empty list for adding images' data\n",
    "    data = []\n",
    "    \n",
    "    # for each frame in the list\n",
    "    for frame in tqdm(frames_list):\n",
    "        # read the image\n",
    "        img = plt.imread(path + frame)\n",
    "        # add it to the data list\n",
    "        data.append(img)\n",
    "    \n",
    "    # convert the list to an array\n",
    "    data = np.array(data)\n",
    "    # normalize the data\n",
    "    data = data / 255\n",
    "    # change the type from float64 (default)\n",
    "    # to float32 to lighten the computations loads\n",
    "    data = data.astype('float32')\n",
    "\n",
    "    # write the result array as a pickle file\n",
    "    with open('./Data_Mini_4Os/pickles/' + name + '.pkl','wb') as file:\n",
    "        pickle.dump(data, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generate the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Paper Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick/Save Random Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66ecfab7abf4864b895b815a74546fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1474.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc2a3c496fc419da2864a7a89dad065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1474.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "917d0cc70e014453a0f8297850fc2351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1474.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5dfdae19964fd6ae041c3616a7dde6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1474.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3bf693da0644c7a96aa8d99b83bc30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1317.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# make a list of the folders in the data directory\n",
    "folders = [name for name in os.listdir('Data_MIT/')]\n",
    "# drop the irrelevant file in the data directory\n",
    "folders.remove('LICENSE.md')\n",
    "folders.remove('README.md')\n",
    "\n",
    "# create an empty list to collect randomly picked\n",
    "# frames from four orientations\n",
    "frames = []\n",
    "# for each orientation\n",
    "for orientation in range(1,5):    \n",
    "    # create a list of valid frames with desired orientation in folders\n",
    "    frames_all = []\n",
    "    for folder in tqdm(folders):\n",
    "        # make a list of valid frames\n",
    "        indices = idx_finder(folder, orientation)\n",
    "        frames_folder = [folder + '-' + (5 - len(str(idx))) * '0' + str(idx) for idx in indices]\n",
    "        frames_all = frames_all + frames_folder\n",
    "\n",
    "    # pick the 10,000 of the frames, randomly\n",
    "    frames_oriented = random.sample(frames_all, 2500)\n",
    "    frames = frames + frames_oriented \n",
    "\n",
    "frames.sort()\n",
    "\n",
    "# create a dictionary of folders (keys) and frames (values-list)\n",
    "# first create a list of the folders\n",
    "folders = sorted(list(set([frame[:5] for frame in frames])))\n",
    "# the create an empty dictionary for saving the frames data\n",
    "frames_dict = {}\n",
    "# iterate over the folders and store each folder's picked frames\n",
    "for folder in folders:\n",
    "    frames_dict[folder] = [frame[-5:] for frame in frames if frame[:5]==folder]\n",
    "    \n",
    "# save the dictionary\n",
    "with open('Data_Mini_4Os/frames_dict.pkl','wb') as f:\n",
    "    pickle.dump(frames_dict, f)\n",
    "    \n",
    "# create a flat list of the frames: folder-frame.jpg in string\n",
    "frames_list = [frame + '.jpg' for frame in frames]\n",
    "\n",
    "# and save that list as well\n",
    "with open('Data_Mini_4Os/frames_list.pkl','wb') as f:\n",
    "    pickle.dump(frames_list, f)\n",
    "\n",
    "# copy-paste sampled frames to the dataset folder\n",
    "for key, val in tqdm(frames_dict.items()):\n",
    "    for frame in val:\n",
    "        copy = './Data_MIT/' + key + '/frames/' + frame + '.jpg'\n",
    "        paste = './Data_Mini_4Os/frames/' + key + '-' + frame + '.jpg'\n",
    "        shutil.copyfile(copy, paste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract/Save the Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539727a91b7f41d39966f8a556053b4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1317.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# list of the json files to read\n",
    "json_list = ['Face', 'LeftEye', 'RightEye']\n",
    "\n",
    "# iterate over folders in dict and frames in folders\n",
    "for key, value in tqdm(frames_dict.items()):\n",
    "    \n",
    "    for idx in value:\n",
    "        \n",
    "        # define the dictionary for recording the info\n",
    "        coords = {}\n",
    "        \n",
    "        # iterate over all json files and read/record the info\n",
    "        for jsn in json_list:\n",
    "            # read each json file\n",
    "            json_reader(coords, jsn, key + '-' + idx)\n",
    "\n",
    "        # adjust the eyes' coordinates to express the location\n",
    "        # for within the frame\n",
    "        coords['LeftEye'][0] += coords['Face'][0]\n",
    "        coords['LeftEye'][1] += coords['Face'][1]\n",
    "        coords['RightEye'][0] += coords['Face'][0]\n",
    "        coords['RightEye'][1] += coords['Face'][1]\n",
    "\n",
    "        # set the path to the image\n",
    "        path = 'Data_Mini_4Os/frames/' + key + '-' + idx + '.jpg'\n",
    "        # read the image\n",
    "        img = cv2.imread(path)\n",
    "        \n",
    "        # iterate over two eyes\n",
    "        for patch in json_list:\n",
    "            # set the save path\n",
    "            save_path = 'Data_Mini_4Os/color_patches/' + patch + '/' + key + '-' + idx + '.jpg' \n",
    "            # save the patch\n",
    "            patch_reader(img, coords[patch], save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract/Save the Paper Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78e2ae07b8f4818874bbdda45c67da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1317.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# iterate over folders in dict and frames in folders\n",
    "for key, value in tqdm(frames_dict.items()):\n",
    "    for idx in value:\n",
    "        # get the grid coordinates\n",
    "        coords = get_coords(key, idx)\n",
    "        # save the grid\n",
    "        grid_paper(coords, key + '-' + idx )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Grayscale Scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the root path to the color patches' folder\n",
    "path_read = './Data_Mini_4Os/color_patches/'\n",
    "# set the root path to the grayscale patches' folder \n",
    "path_write = './Data_Mini_4Os/gray_patches/'\n",
    "\n",
    "# create a list of patch folders' names\n",
    "patches = ['face', 'left_eye', 'right_eye']\n",
    "\n",
    "for patch in patches:\n",
    "    gray(path_read+patch+'/',\n",
    "         path_write+patch+'/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. MTCNN Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get/Save MTCNN Data for the Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the path to the folder\n",
    "path = './Data_Mini_4Os/frames/'\n",
    "# get a list of frames in the folder\n",
    "frames = [name for name in os.listdir(path)]\n",
    "\n",
    "# create an empty list to save the data\n",
    "mtcnn_data = []\n",
    "\n",
    "# for each frame \n",
    "for frame in tqdm(frames):\n",
    "    # read the image\n",
    "    img = plt.imread(path + frame)\n",
    "    # get the MTCNN data\n",
    "    results = MTCNN().detect_faces(img)\n",
    "    # add the frame name to the MTCNN data list\n",
    "    results.append(frame)\n",
    "    \n",
    "    # add the frame's MTCNN data to the final data list \n",
    "    mtcnn_data.append(results)\n",
    "\n",
    "# sort the list regarding the frames' names\n",
    "mtcnn_data.sort(key=itemgetter(-1))\n",
    "\n",
    "# and save the final data list as a pickle file\n",
    "with open('./Data_Mini_4Os/mtcnn_data.pkl','wb') as file:\n",
    "    pickle.dump(mtcnn_data, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the MTCNN data for Unsuccessful Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01366-00923.jpg']\n",
      "['02155-00966.jpg']\n",
      "['02155-01108.jpg']\n",
      "['02364-00414.jpg']\n",
      "['02413-01452.jpg']\n",
      "['02467-00196.jpg']\n",
      "['02522-01390.jpg']\n",
      "['02522-01436.jpg']\n",
      "['02522-01443.jpg']\n"
     ]
    }
   ],
   "source": [
    "# create a list to record the frames with failed mtcnn detection\n",
    "mtcnn_failures = []\n",
    "\n",
    "# for each list in MTCNN data\n",
    "for item in mtcnn_data:\n",
    "    # check the length of the list\n",
    "    # if it's one\n",
    "    if len(item) == 1:\n",
    "        # no face was detected,\n",
    "        # so add the frame name to the failures list\n",
    "        mtcnn_failures.append(item[0])\n",
    "        # drop the item\n",
    "        mtcnn_data.remove(item)\n",
    "        # and also print the failed case\n",
    "        print(item)\n",
    "\n",
    "        \n",
    "# update the frames dictionary and list to remove\n",
    "# the MTCNN failed frames and over-write the pickle files\n",
    "# ----------------------------------------------------------------------\n",
    "# for each frame in the failures list\n",
    "for frame in mtcnn_failures:\n",
    "    \n",
    "    # drop the frame (element in value list) from\n",
    "    # the folder (key) in the frames dictionary \n",
    "    frames_dict[frame[:5]].remove(frame[-9:-4])\n",
    "\n",
    "    # and also drop the frame from the frames_list\n",
    "    frames_list.remove(frame)\n",
    "    \n",
    "# save the frames dictionary\n",
    "with open('Data_Mini_4Os/frames_dict.pkl','wb') as file:\n",
    "    pickle.dump(frames_dict, file)\n",
    "# save the frames list\n",
    "with open('Data_Mini_4Os/frames_list.pkl','wb') as file:\n",
    "    pickle.dump(frames_list, file)\n",
    "# save the MTCNN data\n",
    "with open('Data_Mini_4Os/mtcnn_data.pkl','wb') as file:\n",
    "    pickle.dump(mtcnn_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so, later on I found another problem due to a\n",
    "# mis-detection in the original dataset (one that\n",
    "# should have been tagged as invalid, but it was tagged\n",
    "# valid and while the right eye is totally missing, it\n",
    "# gave another set of coordinate on left eye for the\n",
    "# right eye. Now I'm gonna manually remove that frame\n",
    "# here and re-write the pickel files\n",
    "# -----------------------------------------------------\n",
    "faulty_frame = '02967-02728.jpg'\n",
    "\n",
    "# drop the frame (element in value list) from\n",
    "# the folder (key) in the frames dictionary \n",
    "frames_dict[faulty_frame[:5]].remove(faulty_frame[-9:-4])\n",
    "\n",
    "# drop the frame from the frames_list\n",
    "frames_list.remove(faulty_frame)\n",
    "\n",
    "# and also drop the item from the MTCNN data\n",
    "# check all the items in the list\n",
    "for item in mtcnn_data:\n",
    "    # if the frame name of the item\n",
    "    # is equal to the faulty data\n",
    "    if item[-1] == faulty_frame:\n",
    "        # drop the item\n",
    "        mtcnn_data.remove(item)\n",
    "\n",
    "# save the frames dictionary\n",
    "with open('Data_Mini_4Os/frames_dict.pkl','wb') as file:\n",
    "    pickle.dump(frames_dict, file)\n",
    "# save the frames list\n",
    "with open('Data_Mini_4Os/frames_list.pkl','wb') as file:\n",
    "    pickle.dump(frames_list, file)\n",
    "# save the MTCNN data\n",
    "with open('Data_Mini_4Os/mtcnn_data.pkl','wb') as file:\n",
    "    pickle.dump(mtcnn_data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create/Save MTCNN Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec0cbd3efc2468788d494f2ee8c064b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9991.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# for each detection in MTCNN data\n",
    "for item in tqdm(mtcnn_data):\n",
    "    \n",
    "    # set the plot\n",
    "    ax = plt.gca()\n",
    "    # read the corresponding frame's screen.json file\n",
    "    with open('./Data_MIT/' + item[-1][:5] + '/screen.json', 'r') as file:\n",
    "        screen = json.load(file)\n",
    "    # to check the orientation to get the frame dimensions\n",
    "    orientation = screen['Orientation'][int(item[-1][-9:-4])]\n",
    "\n",
    "    # if the orientation is 1 or 2\n",
    "    if orientation in [1,2]:\n",
    "        # this is a portrait frame, and we\n",
    "        # create a portrait canvas of the same size\n",
    "        canvas = np.ones((640,480))*255\n",
    "    # otherwise\n",
    "    else:\n",
    "        # a landscape frame, and we create\n",
    "        # a landscape canvas of the same size\n",
    "        canvas = np.ones((480,640))*255\n",
    "    \n",
    "    # it may be the case that more than one face is detected\n",
    "    # in the frame, in that case we check the size of face boxes\n",
    "    # and only keep the largest box as the subject face\n",
    "    # -------------------------------------------------\n",
    "    # keep doing until there's only one face detection\n",
    "    # (along with the frame name) left in the item\n",
    "    while len(item) != 2:\n",
    "        # check the first two faces' width\n",
    "        if item[0]['box'][2] > item[1]['box'][2]:\n",
    "            # drop the second one if the first one is bigger\n",
    "            item.pop(1)\n",
    "        # or\n",
    "        else:\n",
    "            # drop the first one if the second one is bigger\n",
    "            item.pop(0)\n",
    "\n",
    "            \n",
    "    # get the facial landmark coordinates\n",
    "    # --------------------------------------------\n",
    "    # get the facebox top-left corner x coordinate\n",
    "    x = item[0]['box'][0]\n",
    "    # get the facebox top-left corner y coordinate\n",
    "    y = item[0]['box'][1]\n",
    "    # get the face box width\n",
    "    width = item[0]['box'][2]\n",
    "    # get the face box height\n",
    "    height = item[0]['box'][3]\n",
    "    # get the (x,y) coordinates of the left eye\n",
    "    left_eye = list(item[0]['keypoints']['left_eye'])\n",
    "    # get the (x,y) coordinates of the right eye\n",
    "    right_eye = list(item[0]['keypoints']['right_eye'])\n",
    "    # get the (x,y) coordinates of the nose\n",
    "    nose = list(item[0]['keypoints']['nose'])\n",
    "\n",
    "    \n",
    "    # generate face box rectangle and eyes-nose triangle patches\n",
    "    # ---------------------------------------------------------------\n",
    "    # draw the face box as a patch in black\n",
    "    rect = Rectangle((x, y), width, height, fill=True, color='black')\n",
    "    # mark the eyes-nose locations as triangle in white\n",
    "    tri = Polygon([left_eye,right_eye,nose], closed=True, fill=True, color='white')\n",
    "    \n",
    "    \n",
    "    # add the patches to the plot\n",
    "    ax.add_patch(rect)\n",
    "    ax.add_patch(tri)\n",
    "    \n",
    "    ax.imshow(canvas, cmap='gray_r')\n",
    "    \n",
    "    # shut down the axis\n",
    "    ax.axis('off')\n",
    "    # and save the image\n",
    "    plt.savefig('./Data_Mini_4Os/grid_mtcnn/' + item[-1],\n",
    "                bbox_inches='tight', pad_inches=0, dpi=212)\n",
    "    \n",
    "    plt.close();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescale MTCNN Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf6c74168a14bdc85b54cda32d2277c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9991.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# for each frame in the list\n",
    "for frame in tqdm(frames_list):\n",
    "    # set the path to the file\n",
    "    path = './Data_Mini_4Os/grid_mtcnn/' + frame\n",
    "    # read the MTCNN original grid\n",
    "    grid = plt.imread(path)\n",
    "    # scale it down\n",
    "    grid = cv2.resize(grid, (50, 50))\n",
    "    # and over-write it\n",
    "    #plt.imsave(path, gird)\n",
    "    plt.imsave(path, grid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create/Save MTCNN Data Point Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty list for recording MTCNN data\n",
    "mtcnn_vector = []\n",
    "\n",
    "# for each frame in frames_list\n",
    "for item in mtcnn_data:\n",
    "    \n",
    "    # it may be the case that more than one face is detected\n",
    "    # in the frame, in that case we check the size of face boxes\n",
    "    # and only keep the largest box as the subject face\n",
    "    # -------------------------------------------------\n",
    "    # keep doing until there's only one face detection\n",
    "    # (along with the frame name) left in the item\n",
    "    while len(item) != 2:\n",
    "        # check the first two faces' width\n",
    "        if item[0]['box'][2] > item[1]['box'][2]:\n",
    "            # drop the second one if the first one is bigger\n",
    "            item.pop(1)\n",
    "        # or\n",
    "        else:\n",
    "            # drop the first one if the second one is bigger\n",
    "            item.pop(0)\n",
    "\n",
    "    # create a list to collect MTCNN data for the frame\n",
    "    data = []\n",
    "    \n",
    "    # get the (x,y) coordinates of the left eye\n",
    "    left_eye = list(item[0]['keypoints']['left_eye'])\n",
    "    # add the left eye data to the list\n",
    "    data = data + left_eye\n",
    "    # get the (x,y) coordinates of the right eye\n",
    "    right_eye = list(item[0]['keypoints']['right_eye'])\n",
    "    # add the right eye data to the list\n",
    "    data = data + right_eye\n",
    "    # get the (x,y) coordinates of the nose\n",
    "    nose = list(item[0]['keypoints']['nose'])\n",
    "    # add the nose data to the list\n",
    "    data = data + nose\n",
    "    \n",
    "    # add frame data list to the final MTCNN data list\n",
    "    mtcnn_vector.append(data)\n",
    "\n",
    "\n",
    "# convert the final list to an np.array\n",
    "mtcnn_vector = np.array(mtcnn_vector)\n",
    "\n",
    "# and save the vector as a pickle file\n",
    "with open('Data_Mini_4Os/pickles/mtcnn_vector.pkl','wb') as file:\n",
    "    pickle.dump(mtcnn_vector, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Nose Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the eyes' patches width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0451326297f54e5b8c17696a3a39812c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9990.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create an empty list for recording frames' eyes'\n",
    "# patches widths so to cut the nose's patch out \n",
    "# with the same size \n",
    "eye_patch_widths = []\n",
    "\n",
    "# for each frame in the list\n",
    "for frame in tqdm(frames_list):\n",
    "    # set the path to the json file\n",
    "    path = './Data_MIT/' + frame[:5]\n",
    "    # set the index to the frame\n",
    "    idx = int(frame[-9:-4])\n",
    "    # read the json file for left eye (both eyes' patches\n",
    "    # have the same dimensions)\n",
    "    with open(path + '/appleLeftEye.json', 'r') as file:\n",
    "        eye_l = json.load(file)\n",
    "    # get the eye's patch width\n",
    "    width = eye_l['W'][idx]\n",
    "    \n",
    "    # add the width and the frame name to the list\n",
    "    eye_patch_widths.append([width, frame])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract/Save Nose Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3159982f1204b2aa47a34985416ff40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9990.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# set the path to read the original frames\n",
    "path_read = './Data_Mini_4Os/frames/'\n",
    "# set the path to write the nose patches\n",
    "path_write = './Data_Mini_4Os/color_patches/nose/'\n",
    "\n",
    "# for 9,991 times:\n",
    "for idx in tqdm(range(9990)):\n",
    "    \n",
    "    # set the path to the frame using the index\n",
    "    read = path_read + mtcnn_data[idx][-1]\n",
    "    # read the frame\n",
    "    img = cv2.imread(read)\n",
    "    \n",
    "    # it may be the case that more than one face is detected\n",
    "    # in the frame, in that case we check the size of face boxes\n",
    "    # and only keep the largest box as the subject face\n",
    "    # -------------------------------------------------\n",
    "    # keep doing until there's only one face detection\n",
    "    # (along with the frame name) left in the item\n",
    "    while len(mtcnn_data[idx]) != 2:\n",
    "        # check the first two faces' width\n",
    "        if mtcnn_data[idx][0]['box'][2] > mtcnn_data[idx][1]['box'][2]:\n",
    "            # drop the second one if the first one is bigger\n",
    "            mtcnn_data[idx].pop(1)\n",
    "        # or\n",
    "        else:\n",
    "            # drop the first one if the second one is bigger\n",
    "            mtcnn_data[idx].pop(0)\n",
    "    \n",
    "    # read the nose coordinates\n",
    "    x, y = list(mtcnn_data[idx][0]['keypoints']['nose'])\n",
    "    \n",
    "    # read the eye patch width and record half its quantity\n",
    "    half_width = round(eye_patch_widths[idx][0]/2)\n",
    "    \n",
    "    # cut out the nose patch\n",
    "    nose = img[y-half_width:y+half_width,\n",
    "               x-half_width:x+half_width]\n",
    "    \n",
    "    # resize the patch\n",
    "    nose = cv2.resize(nose, (64, 64))\n",
    "    \n",
    "    # set the path to save the nose patch\n",
    "    write = path_write + mtcnn_data[idx][-1]\n",
    "    # and finally, save it\n",
    "    cv2.imwrite(write, nose)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generate the Pickle Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e825a0533047e2b14964de33b60321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9990.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056b3b74353040968f5e3fff1f9daae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9990.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d575d7a7ba504ca7ab938114ba8b5e4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9990.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2370d1fb4241dea14e2a50a9b0fbe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9990.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef85fdc5c06415b8b6c987c1e31b18b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9990.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "591dcc92e1bd4fb5bfeb12bb1110d7b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9990.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f454538629994bceaf7abf7f05963872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9990.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# save the color patches as pickle files\n",
    "# -----------------------------------------------\n",
    "# set the path to color patches folder\n",
    "path_parent = './Data_Mini_4Os/color_patches/'\n",
    "\n",
    "# make a list of all folders in color_patches folder\n",
    "folders = ['face', 'left_eye', 'right_eye', 'nose']\n",
    "\n",
    "# for each folder\n",
    "for folder in folders:\n",
    "    # set the path\n",
    "    path = path_parent + folder + '/'\n",
    "    # generate the pickle files for the folder\n",
    "    pickle_write(path, folder)\n",
    "\n",
    "\n",
    "# save the grayscale patches as pickle files\n",
    "# -----------------------------------------------\n",
    "# set the path to grayscale patches folder\n",
    "path_parent = './Data_Mini_4Os/gray_patches/'\n",
    "\n",
    "# make a list of all folders in color_patches folder\n",
    "folders = ['face', 'left_eye', 'right_eye']\n",
    "\n",
    "# for each folder\n",
    "for folder in folders:\n",
    "    # set the path\n",
    "    path = path_parent + folder + '/'\n",
    "    # set the name for the pickle file\n",
    "    name = folder + '_gray'\n",
    "    # generate the pickle files for the folder\n",
    "    pickle_write(path, name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "103241e95736431ea387ee19548beff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9990.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3b53484d114cea9449d7f2a1300a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9990.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# for each grid in the list\n",
    "for grid in ['grid_mtcnn', 'grid_paper']:\n",
    "    \n",
    "    # set the path to the grids' folder\n",
    "    path = './Data_Mini_4Os/' + grid + '/'\n",
    "    \n",
    "    # create an empty list for adding grids' data\n",
    "    data = []\n",
    "\n",
    "    # for each grid in the list\n",
    "    for frame in tqdm(frames_list):\n",
    "        # read the grid\n",
    "        img = plt.imread(path + frame)\n",
    "        # add it to the data list\n",
    "        data.append(img)\n",
    "\n",
    "    # convert the list to an array\n",
    "    data = np.array(data)\n",
    "    \n",
    "    # binarize the grids, cause they're\n",
    "    # kinda blurry after being saved and read\n",
    "    # in such small dimensions\n",
    "    data[data < 128] = 0\n",
    "    data[data >= 128] = 1\n",
    "    # remove the unseless color channel\n",
    "    data = data[:,:,:,0]\n",
    "    \n",
    "    # write the result array as a pickle file\n",
    "    with open('./Data_Mini_4Os/pickles/' + grid + '.pkl','wb') as file:\n",
    "        pickle.dump(data, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dbb5bee0102460c8fe5294712964793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1317.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create a list to store dot/gaze location for each frame\n",
    "labels = []\n",
    "    \n",
    "# iterate over dictionary keys/values and get the labels\n",
    "for key, value in tqdm(frames_dict.items()):\n",
    "    \n",
    "    # set the specific folder's path\n",
    "    path = 'Data_MIT/' + key\n",
    "    \n",
    "    # read the dot json\n",
    "    with open(path + '/dotInfo.json', 'r') as file:\n",
    "        dot = json.load(file)\n",
    "    \n",
    "    # convert the frames list from string to integer\n",
    "    indices_int = [int(idx) for idx in value] \n",
    "    \n",
    "    # for each index in the list\n",
    "    for idx in indices_int:\n",
    "        # add the X and Y values to the list\n",
    "        labels.append([dot['XCam'][idx], dot['YCam'][idx]])\n",
    "\n",
    "        \n",
    "# convert the list to an np.array\n",
    "labels = np.array(labels)\n",
    "\n",
    "# and save it as a pickle file\n",
    "with open('Data_Mini_4Os/labels.pkl','wb') as f:\n",
    "    pickle.dump(labels, f)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
